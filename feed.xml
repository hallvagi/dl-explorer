<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.0.0">Jekyll</generator><link href="https://hallvagi.github.io/dl-explorer/feed.xml" rel="self" type="application/atom+xml" /><link href="https://hallvagi.github.io/dl-explorer/" rel="alternate" type="text/html" /><updated>2020-04-20T07:56:59-05:00</updated><id>https://hallvagi.github.io/dl-explorer/feed.xml</id><title type="html">Deep learning explorer</title><subtitle>Exploring deep learning and data science concepts.</subtitle><entry><title type="html">Fine-tuning a Norwegian language model for ULMFiT</title><link href="https://hallvagi.github.io/dl-explorer/nlp/fastai/lstm/ulmfit/2020/04/20/ULMFiT_langmod.html" rel="alternate" type="text/html" title="Fine-tuning a Norwegian language model for ULMFiT" /><published>2020-04-20T00:00:00-05:00</published><updated>2020-04-20T00:00:00-05:00</updated><id>https://hallvagi.github.io/dl-explorer/nlp/fastai/lstm/ulmfit/2020/04/20/ULMFiT_langmod</id><content type="html" xml:base="https://hallvagi.github.io/dl-explorer/nlp/fastai/lstm/ulmfit/2020/04/20/ULMFiT_langmod.html">&lt;!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-04-20-ULMFiT_langmod.ipynb
--&gt;

&lt;div class=&quot;container&quot; id=&quot;notebook-container&quot;&gt;
        
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;

&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;fastai2.text.all&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h1 id=&quot;ULMFiT-recap&quot;&gt;ULMFiT recap&lt;a class=&quot;anchor-link&quot; href=&quot;#ULMFiT-recap&quot;&gt; &lt;/a&gt;&lt;/h1&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;In a previous post we explored the &lt;a href=&quot;https://github.com/ltgoslo/norec&quot;&gt;Norec&lt;/a&gt; Norwegian language corpus of film and TV reviews. In this post I want to use the &lt;a href=&quot;https://nlp.fast.ai/classification/2018/05/15/introducing-ulmfit.html&quot;&gt;ULMFiT&lt;/a&gt; method to predict the sentiment of the reviews based on the text. ULMFiT has three main steps:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Train a language model on a large general purpose corpus such as Wikipedia&lt;/li&gt;
&lt;li&gt;Fine-tune the language model on the text your are working with - the style is most likely different than a Wikipedia article&lt;/li&gt;
&lt;li&gt;Use the encoder of the fine-tuned language to transform text to feature vectors, and finally add a linear classifier on top to predict the class of the review.&lt;/li&gt;
&lt;/ol&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;In this post we'll focus on step 1 and 2, the language model and the fine-tuning. Training a language model from scratch is a bit of work. First you have to get the data to train it, and the training will also take a long time. Luckily the the fast.ai &lt;a href=&quot;https://forums.fast.ai/t/language-model-zoo-gorilla/14623&quot;&gt;language model zoo&lt;/a&gt; already lists a pretrained language model for Norwegian. Note that this is a ULMFiT model zoo, so we expect to find weights for a &lt;a href=&quot;https://arxiv.org/abs/1708.02182&quot;&gt;AWD-LSTM&lt;/a&gt;. See &lt;a href=&quot;https://hallvagi.github.io/dl-explorer/nlp/fastai/rnn/lstm/2020/04/17/AWD_LSTM.html&quot;&gt;this post&lt;/a&gt; to better understand how to customize an AWD-LSTM with fastai.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Let's first grab the dataset from a &lt;a href=&quot;https://hallvagi.github.io/dl-explorer/nlp/fastai/2020/04/06/get-data.html&quot;&gt;previous post&lt;/a&gt;. It's available as a csv from github:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;https://raw.githubusercontent.com/hallvagi/dl-explorer/master/uploads/norec.csv&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;


&lt;div class=&quot;output_html rendered_html output_subarea output_execute_result&quot;&gt;
&lt;div&gt;
&lt;style scoped=&quot;&quot;&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&quot;1&quot; class=&quot;dataframe&quot;&gt;
  &lt;thead&gt;
    &lt;tr style=&quot;text-align: right;&quot;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;filename&lt;/th&gt;
      &lt;th&gt;rating&lt;/th&gt;
      &lt;th&gt;title&lt;/th&gt;
      &lt;th&gt;split&lt;/th&gt;
      &lt;th&gt;sentiment&lt;/th&gt;
      &lt;th&gt;text&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;html/train/000000.html&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;Rome S02&lt;/td&gt;
      &lt;td&gt;train&lt;/td&gt;
      &lt;td&gt;positive&lt;/td&gt;
      &lt;td&gt;Den andre og siste sesongen av Rome er ute på DVD i Norge. Om du så sesong 1, vet du at du har noe stort i vente. Har du aldri sett Rome før, stikk ut og kjøp begge sesongene. Dette er nemlig en av verdens beste tv-serier, og etter å ha sett de fire første episodene av sesong 2, konstaterer jeg at kvaliteten ser ut til å holde seg på et nesten overraskende høyt nivå! Sesong 2 starter nøyaktig der sesong 1 sluttet. Julius Cæsar ligger myrdet i Senatet og Lucius Vorenus hulker over liket av Neobie. Så blir historien enda mørkere. Marcus Antonius tar over styringen av Roma, men utfordres fra ...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;html/train/000001.html&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;Twin Peaks - definitive gold box edition&lt;/td&gt;
      &lt;td&gt;train&lt;/td&gt;
      &lt;td&gt;positive&lt;/td&gt;
      &lt;td&gt;Tv-serien Twin Peaks, skapt av David Lynch og Mark Frost, trollbandt publikum på starten av 1990-tallet. Nå er begge sesongene samlet på DVD i en såkalt ”definitive gold box edition” som viser at serien ikke har mistet noe av appellen. Det eneste som egentlig røper alderen, er at serien ikke er i widescreen, og at flere av skuespillerne fremdeles er unge og vakre. 17 år etter premieren har de falmet, som mennesker gjør, men Twin Peaks sikrer dem evig liv. Serien handler om et mordmysterium i den lille byen Twin Peaks, et sted langs USAs grense til Canada. Unge, vakre Laura Palmer blir funn...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;html/train/000002.html&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;The Wire (sesong 1-4)&lt;/td&gt;
      &lt;td&gt;train&lt;/td&gt;
      &lt;td&gt;positive&lt;/td&gt;
      &lt;td&gt;I neste uke kommer sesong 5 av tv-serien ”The Wire” på DVD. 2008 har for meg vært sterkt preget av denne serien. Hjemme hos oss begynte vi med sesong 1 i vår. Da hadde jeg i lengre tid hørt panegyriske lovord om serien fra både venner og media. Vi ble også fanget av skildringene av purk og skurk i Baltimore, og pløyde oss igjennom alt til og med sesong 4 på sensommeren. Jeg vil ikke gå så langt som å kalle det ”verdens beste serie”, som noen har gjort, men det er ingen tvil om at dette er noe av det bedre som er blitt vist på tv! Serien forteller om en gruppe politietterforskere som samles...&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h1 id=&quot;Downloading-weights&quot;&gt;Downloading weights&lt;a class=&quot;anchor-link&quot; href=&quot;#Downloading-weights&quot;&gt; &lt;/a&gt;&lt;/h1&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;The pretrained weights we want to use is located in this &lt;a href=&quot;https://github.com/mollerhoj/Scandinavian-ULMFiT&quot;&gt;repo&lt;/a&gt;. There is some information listed here:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The weights were trained on 90% of all text in the corresponding language wikipedia as per 3. July 2018. The remaining 10% was used for validation.&lt;/li&gt;
&lt;li&gt;Norwegian: Trained on 80,284,231 tokens, and validated on 8,920,387 tokens. We achieve a perplexity of 26.31&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;And file descriptions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;enc.h5 Contains the weights in 'Hierarchical Data Format'&lt;/li&gt;
&lt;li&gt;enc.pth Contains the weights in 'Pytorch model format'&lt;/li&gt;
&lt;li&gt;itos.pkl (Integers to Strings) contains the vocabulary mapping from ids (0 - 30000) to strings&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It looks like we will need the enc.pth (fastai is built on top of PyTorch) and the vocabulary (itos.pkl). But how do we actually load the model? The repo doesn't really specify this part, so let's see if we can figure it out. First we'll download and extract the data to a desired location and have a look at the files:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;~/.fastai/data/norec&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# choses a path of your liking!&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;makedirs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;models&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;exist_ok&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model_url&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;https://www.dropbox.com/s/lwr5kvbxri1gvv9/norwegian.zip&amp;#39;&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;wget &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;model_url&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; -O &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;path/&lt;span class=&quot;s1&quot;&gt;&amp;#39;models/norwegian.zip&amp;#39;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; -q
&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;unzip -q &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;path/&lt;span class=&quot;s1&quot;&gt;&amp;#39;models/norwegian.zip&amp;#39;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; -d &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;path/&lt;span class=&quot;s1&quot;&gt;&amp;#39;models&amp;#39;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;BASE_PATH&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;path&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# paths are printed relative to the BASE_PATH&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;models&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ls&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;(#5) [Path(&amp;#39;models/norwegian_wgts.h5&amp;#39;),Path(&amp;#39;models/norwegian_enc.pth&amp;#39;),Path(&amp;#39;models/norwegian.zip&amp;#39;),Path(&amp;#39;models/norwegian_enc.h5&amp;#39;),Path(&amp;#39;models/norwegian_itos.pkl&amp;#39;)]&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Vocabulary&quot;&gt;Vocabulary&lt;a class=&quot;anchor-link&quot; href=&quot;#Vocabulary&quot;&gt; &lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;The first file we want to check out is the norwegian_itos.pkl. This the vocabulary of the model, that is, the words and tokens it's able to recognize. &lt;em&gt;itos&lt;/em&gt; means integer-to-string. The index of a particular token in the list is the key to that token.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;models/norwegian_itos.pkl&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;rb&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;itos&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pickle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;itos&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;itos&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:],&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;itos&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;([&amp;#39;_unk_&amp;#39;, &amp;#39;_pad_&amp;#39;, &amp;#39;.&amp;#39;, &amp;#39;i&amp;#39;, &amp;#39;,&amp;#39;, &amp;#39;og&amp;#39;, &amp;#39;\n\n&amp;#39;, &amp;#39;av&amp;#39;, &amp;#39;som&amp;#39;, &amp;#39;en&amp;#39;],
 [&amp;#39;learning&amp;#39;, &amp;#39;initiativtager&amp;#39;, &amp;#39;forskningsleder&amp;#39;, &amp;#39;devils&amp;#39;, &amp;#39;graeme&amp;#39;],
 30002)&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;The very first token, i.e. index 0, is _unk_ or unknown. The other tokens in the first part of the list are common words such as 'i' (in) and 'og' (and). Among the final tokens there are even some English words. This is not really surprising since Norwegian has &quot;borrowed&quot; several words from English. It seems, however, that the special tokens for unknown and padding (_unk_ and _pad_) are different than the fastai defaults:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;defaults&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text_spec_tok&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;

&lt;div class=&quot;output_subarea output_stream output_stdout output_text&quot;&gt;
&lt;pre&gt;[&amp;#39;xxunk&amp;#39;, &amp;#39;xxpad&amp;#39;, &amp;#39;xxbos&amp;#39;, &amp;#39;xxeos&amp;#39;, &amp;#39;xxfld&amp;#39;, &amp;#39;xxrep&amp;#39;, &amp;#39;xxwrep&amp;#39;, &amp;#39;xxup&amp;#39;, &amp;#39;xxmaj&amp;#39;]
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Will this cause issues later?&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;The-weights&quot;&gt;The weights&lt;a class=&quot;anchor-link&quot; href=&quot;#The-weights&quot;&gt; &lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Secondly, let's have a look at the weights. We'll load it with pyTorch.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;enc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;models/norwegian_enc.pth&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;enc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keys&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;odict_keys([&amp;#39;encoder.weight&amp;#39;, &amp;#39;encoder_dp.emb.weight&amp;#39;, &amp;#39;rnns.0.weight_hh_l0_raw&amp;#39;, &amp;#39;rnns.0.module.weight_ih_l0&amp;#39;, &amp;#39;rnns.0.module.weight_hh_l0&amp;#39;, &amp;#39;rnns.0.module.bias_ih_l0&amp;#39;, &amp;#39;rnns.0.module.bias_hh_l0&amp;#39;, &amp;#39;rnns.1.weight_hh_l0_raw&amp;#39;, &amp;#39;rnns.1.module.weight_ih_l0&amp;#39;, &amp;#39;rnns.1.module.weight_hh_l0&amp;#39;, &amp;#39;rnns.1.module.bias_ih_l0&amp;#39;, &amp;#39;rnns.1.module.bias_hh_l0&amp;#39;, &amp;#39;rnns.2.weight_hh_l0_raw&amp;#39;, &amp;#39;rnns.2.module.weight_ih_l0&amp;#39;, &amp;#39;rnns.2.module.weight_hh_l0&amp;#39;, &amp;#39;rnns.2.module.bias_ih_l0&amp;#39;, &amp;#39;rnns.2.module.bias_hh_l0&amp;#39;])&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;It's a dictionary with keys, and the keys are the names of the layers of the model. We can see that is has an embedding layer (named 'encoder'), and three RNNs(LSTMs more precisely) with various descriptions. We recognize the three layer LSTM from the &lt;a href=&quot;https://arxiv.org/abs/1708.02182&quot;&gt;AWD-LSTM&lt;/a&gt; and the &lt;a href=&quot;https://arxiv.org/abs/1801.06146&quot;&gt;ULMFiT&lt;/a&gt; paper. So we must make sure that the model we set up matches matches this. Let's have a look at the dimensions of the weights.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;enc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;items&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;nb&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot; &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\t&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;

&lt;div class=&quot;output_subarea output_stream output_stdout output_text&quot;&gt;
&lt;pre&gt;encoder.weight  	 torch.Size([30002, 400])
encoder_dp.emb.weight  	 torch.Size([30002, 400])
rnns.0.weight_hh_l0_raw  	 torch.Size([4600, 1150])
rnns.0.module.weight_ih_l0  	 torch.Size([4600, 400])
rnns.0.module.weight_hh_l0  	 torch.Size([4600, 1150])
rnns.0.module.bias_ih_l0  	 torch.Size([4600])
rnns.0.module.bias_hh_l0  	 torch.Size([4600])
rnns.1.weight_hh_l0_raw  	 torch.Size([4600, 1150])
rnns.1.module.weight_ih_l0  	 torch.Size([4600, 1150])
rnns.1.module.weight_hh_l0  	 torch.Size([4600, 1150])
rnns.1.module.bias_ih_l0  	 torch.Size([4600])
rnns.1.module.bias_hh_l0  	 torch.Size([4600])
rnns.2.weight_hh_l0_raw  	 torch.Size([1600, 400])
rnns.2.module.weight_ih_l0  	 torch.Size([1600, 1150])
rnns.2.module.weight_hh_l0  	 torch.Size([1600, 400])
rnns.2.module.bias_ih_l0  	 torch.Size([1600])
rnns.2.module.bias_hh_l0  	 torch.Size([1600])
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;We notice that the hidden size is different than the fastai default of 1152, but apart from that everything looks fine. Let's save a few weights from the embedding layer to compare with our final model.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sample_weights&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;enc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;encoder.weight&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sample_weights&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;tensor([0.5711, 0.2321, 0.2601, 0.9425, 0.0901])&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h1 id=&quot;Load-the-weights-into-our-model&quot;&gt;Load the weights into our model&lt;a class=&quot;anchor-link&quot; href=&quot;#Load-the-weights-into-our-model&quot;&gt; &lt;/a&gt;&lt;/h1&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;First we have to make sure that our data loader uses our custom vocabulary instead of doing tokenization on its own, so we pass &lt;code&gt;text_vocab = itos&lt;/code&gt;. We also set &lt;code&gt;is_lm = True&lt;/code&gt; since we want a language model and not a classifier. We use the basic factory method, since we have no need of customization at this point.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dls_lm&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TextDataLoaders&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;text_col&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;text&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;text_vocab&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;itos&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;is_lm&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;valid_pct&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dls_lm&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show_batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;


&lt;div class=&quot;output_html rendered_html output_subarea &quot;&gt;

&lt;/div&gt;

&lt;/div&gt;

&lt;div class=&quot;output_area&quot;&gt;


&lt;div class=&quot;output_html rendered_html output_subarea &quot;&gt;
&lt;table border=&quot;1&quot; class=&quot;dataframe&quot;&gt;
  &lt;thead&gt;
    &lt;tr style=&quot;text-align: right;&quot;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;text&lt;/th&gt;
      &lt;th&gt;text_&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;_unk_ _unk_ film : i likhet med _unk_ alejandro _unk_ gonzález _unk_ _unk_ « _unk_ » er _unk_ olivier _unk_ _unk_ ' « _unk_ _unk_ maria » et forsøk på å _unk_ spørsmålet om hva som skjer med _unk_ i en tid der de ambisiøse _unk_ _unk_ til tv - skjermen og amerikanske _unk_ dominerer både _unk_ og _unk_ . _unk_ men der « _unk_ » er en high _unk_ - film&lt;/td&gt;
      &lt;td&gt;_unk_ film : i likhet med _unk_ alejandro _unk_ gonzález _unk_ _unk_ « _unk_ » er _unk_ olivier _unk_ _unk_ ' « _unk_ _unk_ maria » et forsøk på å _unk_ spørsmålet om hva som skjer med _unk_ i en tid der de ambisiøse _unk_ _unk_ til tv - skjermen og amerikanske _unk_ dominerer både _unk_ og _unk_ . _unk_ men der « _unk_ » er en high _unk_ - film med&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;på først : _unk_ fordi den franske byen _unk_ calais ligger ved kysten på det stedet hvor _unk_ den engelske kanal er på sitt smaleste , har den blitt invadert av illegale innvandrere fra land som _unk_ afghanistan og _unk_ irak , som etter en _unk_ ferd fra hjemlandet vil forsøke å krysse kanalen og nå _unk_ storbritannia . _unk_ ofte skjuler de seg i lastebiler , noen forsøker å svømme over&lt;/td&gt;
      &lt;td&gt;først : _unk_ fordi den franske byen _unk_ calais ligger ved kysten på det stedet hvor _unk_ den engelske kanal er på sitt smaleste , har den blitt invadert av illegale innvandrere fra land som _unk_ afghanistan og _unk_ irak , som etter en _unk_ ferd fra hjemlandet vil forsøke å krysse kanalen og nå _unk_ storbritannia . _unk_ ofte skjuler de seg i lastebiler , noen forsøker å svømme over .&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;et stort og _unk_ glimt i øyet . _unk_ de spiller aldri hovedrollen selv . _unk_ det er noen år siden herrene _unk_ nils _unk_ _unk_ og _unk_ ronny _unk_ kristoffersen gjorde « _unk_ » . _unk_ nå er de tilbake igjen . _unk_ godt er det . i ni programmer følger vi _unk_ nils og _unk_ ronny gjennom _unk_ colombia , _unk_ gaza , _unk_ england og usas _unk_ _unk_ _unk_&lt;/td&gt;
      &lt;td&gt;stort og _unk_ glimt i øyet . _unk_ de spiller aldri hovedrollen selv . _unk_ det er noen år siden herrene _unk_ nils _unk_ _unk_ og _unk_ ronny _unk_ kristoffersen gjorde « _unk_ » . _unk_ nå er de tilbake igjen . _unk_ godt er det . i ni programmer følger vi _unk_ nils og _unk_ ronny gjennom _unk_ colombia , _unk_ gaza , _unk_ england og usas _unk_ _unk_ _unk_ _unk_&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;This looks pretty good. We can recognize our _unk&lt;em&gt; token for example. We also see that the label column, that is the \&quot;text&lt;/em&gt;&quot; column, is offset by 1 token from the input. This makes sense since the goal of a language model is to predict the next word in a sequence.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;The next step is to configure the AWD-LSTM architecture. Let's have a look at the default config:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;awd_lstm_lm_config&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;{&amp;#39;emb_sz&amp;#39;: 400,
 &amp;#39;n_hid&amp;#39;: 1152,
 &amp;#39;n_layers&amp;#39;: 3,
 &amp;#39;pad_token&amp;#39;: 1,
 &amp;#39;bidir&amp;#39;: False,
 &amp;#39;output_p&amp;#39;: 0.1,
 &amp;#39;hidden_p&amp;#39;: 0.15,
 &amp;#39;input_p&amp;#39;: 0.25,
 &amp;#39;embed_p&amp;#39;: 0.02,
 &amp;#39;weight_p&amp;#39;: 0.2,
 &amp;#39;tie_weights&amp;#39;: True,
 &amp;#39;out_bias&amp;#39;: True}&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Most of these look good, but we will change the n_hid to 1150. Note also the pad_token=1. This is the index of the padding token, and from our itos above we see that &lt;code&gt;itos[1] = _pad_&lt;/code&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;awd_lstm_lm_config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;n_hid&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1150&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Now we can pass the config to our learner object. Notice that we set &lt;code&gt;pretrained=False&lt;/code&gt;, we want to load our own weights. The final &lt;code&gt;.to_fp16()&lt;/code&gt; means that the model is trained with mixed precision (16 bit floating point) which can often speed up training quite a bit.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learn_lm&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;language_model_learner&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dls_lm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                               &lt;span class=&quot;n&quot;&gt;arch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AWD_LSTM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                               &lt;span class=&quot;n&quot;&gt;metrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;accuracy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Perplexity&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()],&lt;/span&gt; 
                               &lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                               &lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;awd_lstm_lm_config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                               &lt;span class=&quot;n&quot;&gt;pretrained&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to_fp16&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;The model summary now looks correct:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learn_lm&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;SequentialRNN(
  (0): AWD_LSTM(
    (encoder): Embedding(30002, 400, padding_idx=1)
    (encoder_dp): EmbeddingDropout(
      (emb): Embedding(30002, 400, padding_idx=1)
    )
    (rnns): ModuleList(
      (0): WeightDropout(
        (module): LSTM(400, 1150, batch_first=True)
      )
      (1): WeightDropout(
        (module): LSTM(1150, 1150, batch_first=True)
      )
      (2): WeightDropout(
        (module): LSTM(1150, 400, batch_first=True)
      )
    )
    (input_dp): RNNDropout()
    (hidden_dps): ModuleList(
      (0): RNNDropout()
      (1): RNNDropout()
      (2): RNNDropout()
    )
  )
  (1): LinearDecoder(
    (decoder): Linear(in_features=400, out_features=30002, bias=True)
    (output_dp): RNNDropout()
  )
)&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;The weights of our model have been initialized randomly, so they should not match at the moment. Let's compare our sample weights from the above section with those from our language model:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learn_lm&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;state_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;0.encoder.weight&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cpu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sample_weights&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;(tensor([-0.0005, -0.0117,  0.0255,  0.0342,  0.0455]),
 tensor([0.5711, 0.2321, 0.2601, 0.9425, 0.0901]))&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;But now we should be able to load the encoder:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learn_lm&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load_encoder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;models/norwegian_enc&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;&amp;lt;fastai2.text.learner.LMLearner at 0x7f518b3bfc10&amp;gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;It worked! We can also see that the weights match:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learn_lm&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;state_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;0.encoder.weight&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cpu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sample_weights&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;(tensor([0.5711, 0.2321, 0.2601, 0.9425, 0.0901]),
 tensor([0.5711, 0.2321, 0.2601, 0.9425, 0.0901]))&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;But are we able to predict any useful text?&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learn_lm&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;Hovedstaden i Norge er&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# the captical of norway is&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;

&lt;div class=&quot;output_subarea output_text output_error&quot;&gt;
&lt;pre&gt;
&lt;span class=&quot;ansi-red-fg&quot;&gt;---------------------------------------------------------------------------&lt;/span&gt;
&lt;span class=&quot;ansi-red-fg&quot;&gt;ValueError&lt;/span&gt;                                Traceback (most recent call last)
&lt;span class=&quot;ansi-green-fg&quot;&gt;&amp;lt;ipython-input-36-d3bf635eccab&amp;gt;&lt;/span&gt; in &lt;span class=&quot;ansi-cyan-fg&quot;&gt;&amp;lt;module&amp;gt;&lt;/span&gt;
&lt;span class=&quot;ansi-green-fg&quot;&gt;----&amp;gt; 1&lt;/span&gt;&lt;span class=&quot;ansi-red-fg&quot;&gt; &lt;/span&gt;learn_lm&lt;span class=&quot;ansi-blue-fg&quot;&gt;.&lt;/span&gt;predict&lt;span class=&quot;ansi-blue-fg&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;ansi-blue-fg&quot;&gt;&amp;#39;Hovedstaden i Norge er&amp;#39;&lt;/span&gt;&lt;span class=&quot;ansi-blue-fg&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;ansi-green-fg&quot;&gt;~/git/fastai2/fastai2/text/learner.py&lt;/span&gt; in &lt;span class=&quot;ansi-cyan-fg&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;ansi-blue-fg&quot;&gt;(self, text, n_words, no_unk, temperature, min_p, no_bar, decoder, only_last_word)&lt;/span&gt;
&lt;span class=&quot;ansi-green-intense-fg ansi-bold&quot;&gt;    159&lt;/span&gt;         self&lt;span class=&quot;ansi-blue-fg&quot;&gt;.&lt;/span&gt;model&lt;span class=&quot;ansi-blue-fg&quot;&gt;.&lt;/span&gt;reset&lt;span class=&quot;ansi-blue-fg&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;ansi-blue-fg&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;ansi-green-intense-fg ansi-bold&quot;&gt;    160&lt;/span&gt;         idxs &lt;span class=&quot;ansi-blue-fg&quot;&gt;=&lt;/span&gt; idxs_all &lt;span class=&quot;ansi-blue-fg&quot;&gt;=&lt;/span&gt; self&lt;span class=&quot;ansi-blue-fg&quot;&gt;.&lt;/span&gt;dls&lt;span class=&quot;ansi-blue-fg&quot;&gt;.&lt;/span&gt;test_dl&lt;span class=&quot;ansi-blue-fg&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;ansi-blue-fg&quot;&gt;[&lt;/span&gt;text&lt;span class=&quot;ansi-blue-fg&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;ansi-blue-fg&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;ansi-blue-fg&quot;&gt;.&lt;/span&gt;items&lt;span class=&quot;ansi-blue-fg&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;ansi-cyan-fg&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;ansi-blue-fg&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;ansi-blue-fg&quot;&gt;.&lt;/span&gt;to&lt;span class=&quot;ansi-blue-fg&quot;&gt;(&lt;/span&gt;self&lt;span class=&quot;ansi-blue-fg&quot;&gt;.&lt;/span&gt;dls&lt;span class=&quot;ansi-blue-fg&quot;&gt;.&lt;/span&gt;device&lt;span class=&quot;ansi-blue-fg&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;ansi-green-fg&quot;&gt;--&amp;gt; 161&lt;/span&gt;&lt;span class=&quot;ansi-red-fg&quot;&gt;         &lt;/span&gt;&lt;span class=&quot;ansi-green-fg&quot;&gt;if&lt;/span&gt; no_unk&lt;span class=&quot;ansi-blue-fg&quot;&gt;:&lt;/span&gt; unk_idx &lt;span class=&quot;ansi-blue-fg&quot;&gt;=&lt;/span&gt; self&lt;span class=&quot;ansi-blue-fg&quot;&gt;.&lt;/span&gt;dls&lt;span class=&quot;ansi-blue-fg&quot;&gt;.&lt;/span&gt;vocab&lt;span class=&quot;ansi-blue-fg&quot;&gt;.&lt;/span&gt;index&lt;span class=&quot;ansi-blue-fg&quot;&gt;(&lt;/span&gt;UNK&lt;span class=&quot;ansi-blue-fg&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;ansi-green-intense-fg ansi-bold&quot;&gt;    162&lt;/span&gt;         &lt;span class=&quot;ansi-green-fg&quot;&gt;for&lt;/span&gt; _ &lt;span class=&quot;ansi-green-fg&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;ansi-blue-fg&quot;&gt;(&lt;/span&gt;range&lt;span class=&quot;ansi-blue-fg&quot;&gt;(&lt;/span&gt;n_words&lt;span class=&quot;ansi-blue-fg&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;ansi-green-fg&quot;&gt;if&lt;/span&gt; no_bar &lt;span class=&quot;ansi-green-fg&quot;&gt;else&lt;/span&gt; progress_bar&lt;span class=&quot;ansi-blue-fg&quot;&gt;(&lt;/span&gt;range&lt;span class=&quot;ansi-blue-fg&quot;&gt;(&lt;/span&gt;n_words&lt;span class=&quot;ansi-blue-fg&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;ansi-blue-fg&quot;&gt;,&lt;/span&gt; leave&lt;span class=&quot;ansi-blue-fg&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;ansi-green-fg&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;ansi-blue-fg&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;ansi-blue-fg&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;ansi-blue-fg&quot;&gt;:&lt;/span&gt;
&lt;span class=&quot;ansi-green-intense-fg ansi-bold&quot;&gt;    163&lt;/span&gt;             &lt;span class=&quot;ansi-green-fg&quot;&gt;with&lt;/span&gt; self&lt;span class=&quot;ansi-blue-fg&quot;&gt;.&lt;/span&gt;no_bar&lt;span class=&quot;ansi-blue-fg&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;ansi-blue-fg&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;ansi-blue-fg&quot;&gt;:&lt;/span&gt; preds&lt;span class=&quot;ansi-blue-fg&quot;&gt;,&lt;/span&gt;_ &lt;span class=&quot;ansi-blue-fg&quot;&gt;=&lt;/span&gt; self&lt;span class=&quot;ansi-blue-fg&quot;&gt;.&lt;/span&gt;get_preds&lt;span class=&quot;ansi-blue-fg&quot;&gt;(&lt;/span&gt;dl&lt;span class=&quot;ansi-blue-fg&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;ansi-blue-fg&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;ansi-blue-fg&quot;&gt;(&lt;/span&gt;idxs&lt;span class=&quot;ansi-blue-fg&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;ansi-green-fg&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;ansi-blue-fg&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;ansi-blue-fg&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;ansi-blue-fg&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;ansi-blue-fg&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;ansi-blue-fg&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;ansi-red-fg&quot;&gt;ValueError&lt;/span&gt;: &amp;#39;xxunk&amp;#39; is not in list&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;What is the problem now? We see that &lt;code&gt;predict()&lt;/code&gt; by default has &lt;code&gt;no_unk=True&lt;/code&gt;. The error message tells us that the library tries to get the index of the UNK token. The UNK token is as we noted earlier different in our &lt;code&gt;itos&lt;/code&gt; (vocabulary) than that what the library expects&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;UNK&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;itos&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;(&amp;#39;xxunk&amp;#39;, &amp;#39;_unk_&amp;#39;)&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;This is not really a problem for our model. The models only sees the underlying numbers and indexes, and they are still correct. But if we want to use most of the convenience functions of the fastai2 library, we either have to customise the code, or simpler still, change the vocab.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Replace-special-tokens-in-vocab&quot;&gt;Replace special tokens in vocab&lt;a class=&quot;anchor-link&quot; href=&quot;#Replace-special-tokens-in-vocab&quot;&gt; &lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;So let's look through our itos and see if we can find any special tokens:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;defaults&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text_spec_tok&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# fastai defaults&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;

&lt;div class=&quot;output_subarea output_stream output_stdout output_text&quot;&gt;
&lt;pre&gt;[&amp;#39;xxunk&amp;#39;, &amp;#39;xxpad&amp;#39;, &amp;#39;xxbos&amp;#39;, &amp;#39;xxeos&amp;#39;, &amp;#39;xxfld&amp;#39;, &amp;#39;xxrep&amp;#39;, &amp;#39;xxwrep&amp;#39;, &amp;#39;xxup&amp;#39;, &amp;#39;xxmaj&amp;#39;]
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Let's look for tokens that contains an underscore &lt;strong&gt;_&lt;/strong&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_toks&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;token&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;token&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;itos&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;_&amp;#39;&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;token&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;_toks&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;[&amp;#39;_unk_&amp;#39;, &amp;#39;_pad_&amp;#39;, &amp;#39;t_up&amp;#39;, &amp;#39;tk_rep&amp;#39;, &amp;#39;formula_1&amp;#39;]&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;And then for tokens that begin with an &lt;strong&gt;x&lt;/strong&gt;. We use a simple regex to check for x in the beginning of the token.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_toks&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;token&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;token&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;itos&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;match&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;^x&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;token&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x_toks&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;[&amp;#39;xfld&amp;#39;, &amp;#39;xbos&amp;#39;, &amp;#39;x&amp;#39;, &amp;#39;xii&amp;#39;, &amp;#39;xi&amp;#39;]&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;'&lt;em&gt;unk&lt;/em&gt;', '&lt;em&gt;pad&lt;/em&gt;', 'xfld', 'xbos' seems pretty obvious. But I'm less sure of eg. 't_up' and 'tk_rep'. So we replace a bit conservatively:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to_replace&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_toks&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_toks&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;to_replace&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;[&amp;#39;_unk_&amp;#39;, &amp;#39;_pad_&amp;#39;, &amp;#39;xfld&amp;#39;, &amp;#39;xbos&amp;#39;]&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;replace_with&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;defaults&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text_spec_tok&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;defaults&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text_spec_tok&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;defaults&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text_spec_tok&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;replace_with&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;[&amp;#39;xxunk&amp;#39;, &amp;#39;xxpad&amp;#39;, &amp;#39;xxup&amp;#39;, &amp;#39;xxbos&amp;#39;]&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Then we loop trough our itos and replace the selected tokens:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tok_remove&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tok_insert&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to_replace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;replace_with&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;itos&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tok_remove&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;itos&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tok_insert&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;To verify that we did things correct:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idxs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;itos&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;token&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;token&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;replace_with&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;idxs&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;[0, 1, 31, 32]&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;itos&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;idxs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;[&amp;#39;xxunk&amp;#39;, &amp;#39;xxpad&amp;#39;, &amp;#39;xxup&amp;#39;, &amp;#39;xxbos&amp;#39;]&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Language-model:-final-cut&quot;&gt;Language model: final cut&lt;a class=&quot;anchor-link&quot; href=&quot;#Language-model:-final-cut&quot;&gt; &lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Let's make yet another version of our dataloader and language learner.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dls_lm&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TextDataLoaders&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;text_col&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;text&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;text_vocab&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;itos&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;is_lm&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;valid_pct&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;learn_lm&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;language_model_learner&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dls_lm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;arch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AWD_LSTM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;metrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;accuracy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Perplexity&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()],&lt;/span&gt; 
                               &lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;awd_lstm_lm_config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pretrained&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to_fp16&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;learn_lm&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load_encoder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;models/norwegian_enc&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;


&lt;div class=&quot;output_html rendered_html output_subarea &quot;&gt;

&lt;/div&gt;

&lt;/div&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;&amp;lt;fastai2.text.learner.LMLearner at 0x7f511dc73b50&amp;gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;TEXT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;Hovedstaden i Norge er&amp;quot;&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# the capital of norway is&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;preds&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learn_lm&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;TEXT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;40&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;temperature&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.75&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;preds&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;


&lt;div class=&quot;output_html rendered_html output_subarea &quot;&gt;

&lt;/div&gt;

&lt;/div&gt;

&lt;div class=&quot;output_area&quot;&gt;


&lt;div class=&quot;output_html rendered_html output_subarea &quot;&gt;

&lt;/div&gt;

&lt;/div&gt;

&lt;div class=&quot;output_area&quot;&gt;


&lt;div class=&quot;output_html rendered_html output_subarea &quot;&gt;

&lt;/div&gt;

&lt;/div&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;[&amp;#39;hovedstaden i norge er en by med stor politisk status fra 1891 til 1955 . \n \n 1 havene \n\n havene ( engelsk &amp;#34; american mountains &amp;#34; , engelsk : &amp;#34; mountain peninsula &amp;#34; eller &amp;#34; t_up ngc &amp;#34; eller &amp;#34; øvre&amp;#39;,
 &amp;#39;hovedstaden i norge er \n \n 1 hans - herman \n\n hans - günther ( født 28 . desember 1812 i rostock , død 6 . desember 1888 i leipzig ) var en tysk økonom , som var general og generaldirektør for&amp;#39;,
 &amp;#39;hovedstaden i norge er oppkalt etter ham . i tillegg er det ett av norges høyeste byer og omegn . i norge er det også en rekke andre land : \n\n historie . \n det er i dag i norge ikke lenger en kommunal&amp;#39;]&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Well, that kind of makes sense. LSTMs are less capable at generating text than the more complex transformer architectures, but our concern in this particular case is how well we eventually do sentiment classification.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h1 id=&quot;Fine-tune-model&quot;&gt;Fine tune model&lt;a class=&quot;anchor-link&quot; href=&quot;#Fine-tune-model&quot;&gt; &lt;/a&gt;&lt;/h1&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Now we are finally ready to fine tune our language model. We'll use the &quot;standard&quot; training regime from the documentation and the fast.ai courses. That is 1 epoch where only the linear layers in the head of the model are trainable, and finally 10 epochs with all layers unfrozen.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learn_lm&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lr_find&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;


&lt;div class=&quot;output_html rendered_html output_subarea &quot;&gt;

&lt;/div&gt;

&lt;/div&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;SuggestedLRs(lr_min=0.02089296132326126, lr_steep=1.3182567499825382e-06)&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_png output_subarea &quot;&gt;
&lt;img src=&quot;data:image/png;base64,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
&quot; /&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;A learning rate of 1e-2 seem to be a safe choice:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learn_lm&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit_one_cycle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1e-2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;


&lt;div class=&quot;output_html rendered_html output_subarea &quot;&gt;
&lt;table border=&quot;1&quot; class=&quot;dataframe&quot;&gt;
  &lt;thead&gt;
    &lt;tr style=&quot;text-align: left;&quot;&gt;
      &lt;th&gt;epoch&lt;/th&gt;
      &lt;th&gt;train_loss&lt;/th&gt;
      &lt;th&gt;valid_loss&lt;/th&gt;
      &lt;th&gt;accuracy&lt;/th&gt;
      &lt;th&gt;perplexity&lt;/th&gt;
      &lt;th&gt;time&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;4.189573&lt;/td&gt;
      &lt;td&gt;3.936918&lt;/td&gt;
      &lt;td&gt;0.315999&lt;/td&gt;
      &lt;td&gt;51.260372&lt;/td&gt;
      &lt;td&gt;02:35&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Next we will unfreeze all layers and train for 10 epochs at a reduced learning rate. The idea is that once we unfreeze the lower layers of our model we should make smaller changes to avoid catastrophic forgetting. We will go for a leraning rate of 1e-3. One can always test if longer training improves results, but in this case we will simply assumes that 10 epochs is good enough.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learn_lm&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unfreeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;learn_lm&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lr_find&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;


&lt;div class=&quot;output_html rendered_html output_subarea &quot;&gt;

&lt;/div&gt;

&lt;/div&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;SuggestedLRs(lr_min=0.0003019951749593019, lr_steep=6.309573450380412e-07)&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_png output_subarea &quot;&gt;
&lt;img src=&quot;data:image/png;base64,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
&quot; /&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learn_lm&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit_one_cycle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1e-3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;


&lt;div class=&quot;output_html rendered_html output_subarea &quot;&gt;
&lt;table border=&quot;1&quot; class=&quot;dataframe&quot;&gt;
  &lt;thead&gt;
    &lt;tr style=&quot;text-align: left;&quot;&gt;
      &lt;th&gt;epoch&lt;/th&gt;
      &lt;th&gt;train_loss&lt;/th&gt;
      &lt;th&gt;valid_loss&lt;/th&gt;
      &lt;th&gt;accuracy&lt;/th&gt;
      &lt;th&gt;perplexity&lt;/th&gt;
      &lt;th&gt;time&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;3.997230&lt;/td&gt;
      &lt;td&gt;3.822397&lt;/td&gt;
      &lt;td&gt;0.327288&lt;/td&gt;
      &lt;td&gt;45.713673&lt;/td&gt;
      &lt;td&gt;02:47&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;3.954266&lt;/td&gt;
      &lt;td&gt;3.777179&lt;/td&gt;
      &lt;td&gt;0.330856&lt;/td&gt;
      &lt;td&gt;43.692589&lt;/td&gt;
      &lt;td&gt;02:48&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;3.878042&lt;/td&gt;
      &lt;td&gt;3.725606&lt;/td&gt;
      &lt;td&gt;0.337251&lt;/td&gt;
      &lt;td&gt;41.496380&lt;/td&gt;
      &lt;td&gt;02:38&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;3.814440&lt;/td&gt;
      &lt;td&gt;3.686008&lt;/td&gt;
      &lt;td&gt;0.340614&lt;/td&gt;
      &lt;td&gt;39.885315&lt;/td&gt;
      &lt;td&gt;02:47&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;3.785215&lt;/td&gt;
      &lt;td&gt;3.656684&lt;/td&gt;
      &lt;td&gt;0.344700&lt;/td&gt;
      &lt;td&gt;38.732697&lt;/td&gt;
      &lt;td&gt;02:41&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;3.729483&lt;/td&gt;
      &lt;td&gt;3.635671&lt;/td&gt;
      &lt;td&gt;0.346845&lt;/td&gt;
      &lt;td&gt;37.927280&lt;/td&gt;
      &lt;td&gt;02:43&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;3.698734&lt;/td&gt;
      &lt;td&gt;3.618694&lt;/td&gt;
      &lt;td&gt;0.348383&lt;/td&gt;
      &lt;td&gt;37.288837&lt;/td&gt;
      &lt;td&gt;02:46&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;7&lt;/td&gt;
      &lt;td&gt;3.654537&lt;/td&gt;
      &lt;td&gt;3.607326&lt;/td&gt;
      &lt;td&gt;0.350624&lt;/td&gt;
      &lt;td&gt;36.867321&lt;/td&gt;
      &lt;td&gt;02:48&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;8&lt;/td&gt;
      &lt;td&gt;3.635801&lt;/td&gt;
      &lt;td&gt;3.602736&lt;/td&gt;
      &lt;td&gt;0.351033&lt;/td&gt;
      &lt;td&gt;36.698505&lt;/td&gt;
      &lt;td&gt;02:49&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;9&lt;/td&gt;
      &lt;td&gt;3.618312&lt;/td&gt;
      &lt;td&gt;3.601928&lt;/td&gt;
      &lt;td&gt;0.351133&lt;/td&gt;
      &lt;td&gt;36.668865&lt;/td&gt;
      &lt;td&gt;02:50&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;&lt;div class=&quot;flash&quot;&gt;
    &lt;svg class=&quot;octicon octicon-info octicon octicon-info&quot; viewBox=&quot;0 0 14 16&quot; version=&quot;1.1&quot; width=&quot;14&quot; height=&quot;16&quot; aria-hidden=&quot;true&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M6.3 5.69a.942.942 0 01-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 01-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;
    &lt;strong&gt;Note: &lt;/strong&gt;We&amp;#8217;re only training for about 30 minutes on a single GPU.
&lt;/div&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;We will save the model and the encoder for future use. The &lt;code&gt;save()&lt;/code&gt; method save objects to path/'models' by default. The encoder will be used in our classifier in the next post.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learn_lm&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;save&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;finetuned_model&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;learn_lm&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;save_encoder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;finetuned_encoder&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Is the model any good at predicting text?&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;TEXT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;Denne filmen er et godt eksempel på&amp;quot;&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# this film is a good example of&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;preds&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learn_lm&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;TEXT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;40&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;temperature&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.75&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;preds&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;


&lt;div class=&quot;output_html rendered_html output_subarea &quot;&gt;

&lt;/div&gt;

&lt;/div&gt;

&lt;div class=&quot;output_area&quot;&gt;


&lt;div class=&quot;output_html rendered_html output_subarea &quot;&gt;

&lt;/div&gt;

&lt;/div&gt;

&lt;div class=&quot;output_area&quot;&gt;


&lt;div class=&quot;output_html rendered_html output_subarea &quot;&gt;

&lt;/div&gt;

&lt;/div&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;[&amp;#39;xxunk denne filmen er et godt eksempel på hvordan serien er blitt laget med en amerikansk komedie . i filmen står det en tydelig og effektiv følelse av at en serie med tretten mennesker , som har mistet kontrollen over de to første episodene , har fått en&amp;#39;,
 &amp;#39;xxunk denne filmen er et godt eksempel på hva som skjer når den kommer i nærheten av en tsunami . i verste fall skjer det med den virkelige verden , hvor det som skjer , er det som gjør at den blir rammet av et stadig forvirrende ,&amp;#39;,
 &amp;#39;xxunk denne filmen er et godt eksempel på at det er vanskelig å forestille seg hva som egentlig foregår . i visse scener er dette en underholdende og ytterst underholdende film , i norsk forstand . JON GORE « the THAT IN&amp;#39;]&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;This is by no means as impressive as the recent transformer models, but the model certainly understands language fairly well. Also, our particular use case isn't really text generation, but sentiment classification. Transformers only do marginally better than ULMFiT according to &lt;a href=&quot;https://paperswithcode.com/sota/sentiment-analysis-on-imdb&quot;&gt;Papers with code&lt;/a&gt; on the similar IMDB classification task. Classification will be the topic of an upcoming post.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name></name></author><summary type="html"></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://hallvagi.github.io/dl-explorer/images/some_folder/your_image.png" /><media:content medium="image" url="https://hallvagi.github.io/dl-explorer/images/some_folder/your_image.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">A code-first inspection of the AWD-LSTM</title><link href="https://hallvagi.github.io/dl-explorer/nlp/fastai/rnn/lstm/2020/04/17/AWD_LSTM.html" rel="alternate" type="text/html" title="A code-first inspection of the AWD-LSTM" /><published>2020-04-17T00:00:00-05:00</published><updated>2020-04-17T00:00:00-05:00</updated><id>https://hallvagi.github.io/dl-explorer/nlp/fastai/rnn/lstm/2020/04/17/AWD_LSTM</id><content type="html" xml:base="https://hallvagi.github.io/dl-explorer/nlp/fastai/rnn/lstm/2020/04/17/AWD_LSTM.html">&lt;!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-04-17-AWD_LSTM.ipynb
--&gt;

&lt;div class=&quot;container&quot; id=&quot;notebook-container&quot;&gt;
        
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;

&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;fastai2.text.all&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h1 id=&quot;ULMFiT&quot;&gt;ULMFiT&lt;a class=&quot;anchor-link&quot; href=&quot;#ULMFiT&quot;&gt; &lt;/a&gt;&lt;/h1&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;In the previous post we explored the &lt;a href=&quot;https://github.com/ltgoslo/norec&quot;&gt;Norec&lt;/a&gt; Norwegian language corpus. We grabbed the reviews for films and TV-shows, parsed the html-text and created labels based on the ratings. In the next few posts I want to use &lt;a href=&quot;https://nlp.fast.ai/classification/2018/05/15/introducing-ulmfit.html&quot;&gt;ULMFiT&lt;/a&gt; and other methods to predict the sentiment of the reviews based on the text.&lt;br /&gt;
ULMFiT has three main steps:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Train a language model on a large general purpose corpus such as Wikipedia&lt;/li&gt;
&lt;li&gt;Fine-tune the language model on the text your are working with - the style is most likely different than a Wikipedia article&lt;/li&gt;
&lt;li&gt;Combine the encoder of the fine-tuned language model with a linear classifier to predict the class of your text&lt;/li&gt;
&lt;/ol&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;The core of the ULMFiT method is a type of Recurrent neural network (RNN) called &lt;a href=&quot;https://arxiv.org/abs/1708.02182&quot;&gt;AWD-LSTM&lt;/a&gt;. AWD-LSTM is a special kind of Recurrent neural network (RNN) with tuned dropout parameters among other. We need to look into this architecture before we continue with our modeling. For an explanation of what an &lt;em&gt;LSTM&lt;/em&gt; actually is i suggest checking out this &lt;a href=&quot;https://colah.github.io/posts/2015-08-Understanding-LSTMs/&quot;&gt;blog post&lt;/a&gt; by Chris Olah. In general, most of Chris' posts and papers are worth reading!&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h1 id=&quot;How-to-set-up-an-AWD-LSTM-with-fastai&quot;&gt;How to set up an AWD-LSTM with fastai&lt;a class=&quot;anchor-link&quot; href=&quot;#How-to-set-up-an-AWD-LSTM-with-fastai&quot;&gt; &lt;/a&gt;&lt;/h1&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Let's first start by inspecting fastai's &lt;code&gt;language_model_learner&lt;/code&gt;. It's a learner class designed to be used for language models, and holds both dataloaders and the architecture along with various hyperparameters. We can use the &lt;code&gt;doc()&lt;/code&gt; method to show us the &lt;a href=&quot;https://dev.fast.ai/text.learner#Learner-convenience-functions&quot;&gt;documentation&lt;/a&gt;:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;doc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;language_model_learner&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;The documentation tells us that we can pass &lt;code&gt;arch = AWD-LSTM&lt;/code&gt; and modify the &lt;code&gt;awd_lstm_lm_config&lt;/code&gt; to customize the architecture. The config dictionary specifies various hyperparameters and settings inspired by the aforementioned AWD-LSTM paper. By changing this dictionary we can customize our AWD-LSTM to fit our specific needs:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;awd_lstm_lm_config&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;{&amp;#39;emb_sz&amp;#39;: 400,
 &amp;#39;n_hid&amp;#39;: 1152,
 &amp;#39;n_layers&amp;#39;: 3,
 &amp;#39;pad_token&amp;#39;: 1,
 &amp;#39;bidir&amp;#39;: False,
 &amp;#39;output_p&amp;#39;: 0.1,
 &amp;#39;hidden_p&amp;#39;: 0.15,
 &amp;#39;input_p&amp;#39;: 0.25,
 &amp;#39;embed_p&amp;#39;: 0.02,
 &amp;#39;weight_p&amp;#39;: 0.2,
 &amp;#39;tie_weights&amp;#39;: True,
 &amp;#39;out_bias&amp;#39;: True}&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Let's check the &lt;a href=&quot;https://dev.fast.ai/text.models.awdlstm#AWD_LSTM&quot;&gt;documentation&lt;/a&gt; and source code of the AWD-LSTM class. You can check the source code directly in the notebook by appending a &lt;code&gt;??&lt;/code&gt; behind the method name:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;AWD_LSTM&lt;span class=&quot;o&quot;&gt;??&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;The source code shows us a few interesting lines we'll look more into in the next few sections:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;self.encoder = nn.Embedding(vocab_sz, emb_sz, padding_idx=pad_token)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;self.rnns = nn.ModuleList([self._one_rnn(emb_sz if l == 0 else n_hid, (n_hid if l != n_layers - 1 else emb_sz)//self.n_dir, bidir, weight_p, l) for l in range(n_layers)])&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;self.input_dp = RNNDropout(input_p)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;self.hidden_dps = nn.ModuleList([RNNDropout(hidden_p) for l in range(n_layers)])&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;&lt;div class=&quot;flash&quot;&gt;
    &lt;svg class=&quot;octicon octicon-info&quot; viewBox=&quot;0 0 14 16&quot; version=&quot;1.1&quot; width=&quot;14&quot; height=&quot;16&quot; aria-hidden=&quot;true&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M6.3 5.69a.942.942 0 01-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 01-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;
    &lt;strong&gt;Note: &lt;/strong&gt;the embedding is called encoder in the code above. The name encoder is also fastai lingo for the entire RNN-part of the architecture. The linear layers added on top for the classifier is called decoder. Neither the ULMFiT or AWD-LSTM paper uses the term encoder or decoder though.
&lt;/div&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;But-what-is-an-embedding?&quot;&gt;But what is an embedding?&lt;a class=&quot;anchor-link&quot; href=&quot;#But-what-is-an-embedding?&quot;&gt; &lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Once again I'll be lazy and rather refer to another &lt;a href=&quot;http://jalammar.github.io/illustrated-word2vec/&quot;&gt;blog&lt;/a&gt; that explains embeddings in detail. The blog is by Jay Alammar and has explanations of many deep learning and NLP concepts. The essence is that we'll turn each token in our vocabulary into a vector of some size that represents various aspects of that token. The weights of this vector will be trainable and gives our neural network a lot of flexibility in assigning various properties to each token.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;The embedding is created by: &lt;code&gt;self.encoder = nn.Embedding(vocab_sz, emb_sz, padding_idx=pad_token)&lt;/code&gt; Here we see that fastai is built on top of pyTorch and relies on pyTorch's fundamental methods in its own code. The encoder layer is a call to &lt;code&gt;nn.Embedding&lt;/code&gt;, see &lt;a href=&quot;https://pytorch.org/docs/stable/nn.html#normalization-layers&quot;&gt;documentation&lt;/a&gt;. Let's create an embedding of size 10x3 with padding_idx = 0:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;embedding&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Embedding&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_embeddings&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;embedding_dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;padding_idx&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;embedding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weight&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;Parameter containing:
tensor([[ 0.0000,  0.0000,  0.0000],
        [ 1.6721, -1.3130,  0.6414],
        [ 1.1675,  0.1174,  1.8511],
        [-0.3341, -1.0047, -0.8467],
        [-0.7737, -0.3947, -1.5273],
        [-1.1472, -0.0429, -0.0994],
        [-1.0594,  1.3725,  0.3796],
        [ 0.1682,  0.7212,  0.9494],
        [ 1.2791,  0.1334, -0.5075],
        [ 0.4486,  0.4936,  0.2588]], requires_grad=True)&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;The embedding now has 10 vectors of length 3 with randomly initialized weights. Note that the first one (index 0) is all 0. This is because 0 is our padding index. Next we'll pass some some sample data &lt;code&gt;inp&lt;/code&gt;, and inspect the result. We can think of our input as the index of words in a dictionary. E.g. 1='this', 7='is', 4='not' and 3='easy'. 0 will be our padding token. The padding token is a special token that is used to ensure that some text has a certain length. This is useful when stacking various pieces of text into a batch where sizes needs to match.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LongTensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;emb&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;embedding&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;emb&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;tensor([[ 1.6721, -1.3130,  0.6414],
        [ 0.1682,  0.7212,  0.9494],
        [-0.7737, -0.3947, -1.5273],
        [-0.3341, -1.0047, -0.8467],
        [ 0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000]], grad_fn=&amp;lt;EmbeddingBackward&amp;gt;)&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;We see that the embedding produced by feeding the input corresponds to the weights of our original embedding. That is, index 1 of &lt;code&gt;inp&lt;/code&gt; is the item '7'. So &lt;code&gt;emb[1]&lt;/code&gt; is basically a lookup for &lt;code&gt;embedding.weight[7]&lt;/code&gt;.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;embedding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weight&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;emb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;(tensor([0.1682, 0.7212, 0.9494], grad_fn=&amp;lt;SelectBackward&amp;gt;),
 tensor([0.1682, 0.7212, 0.9494], grad_fn=&amp;lt;SelectBackward&amp;gt;))&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;blockquote&gt;&lt;p&gt;To summarize:We'll need an embedding with the number of embeddings equal to our vocabulary size, and embedding size of 400 and a padding token-id which corresponds to whichever token has been used as padding in our vocabulary.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Compostion-of-the-RNN-layers&quot;&gt;Compostion of the RNN-layers&lt;a class=&quot;anchor-link&quot; href=&quot;#Compostion-of-the-RNN-layers&quot;&gt; &lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Secondly we create a list of RNN-layers with various dimensions:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rnns&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ModuleList&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_one_rnn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;emb_sz&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_hid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                         &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_hid&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_layers&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;emb_sz&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;//&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_dir&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bidir&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;weight_p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_layers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The code stacks RNN-layers of &lt;code&gt;embedding size x hidden size&lt;/code&gt; for the first layer, and &lt;code&gt;hidden size x embedding size&lt;/code&gt; for the final. Let's verify that this works for various number of layers:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AWD_LSTM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vocab_sz&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10_000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;emb_sz&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;400&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_hid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1152&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_layers&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;AWD_LSTM(
  (encoder): Embedding(10000, 400, padding_idx=1)
  (encoder_dp): EmbeddingDropout(
    (emb): Embedding(10000, 400, padding_idx=1)
  )
  (rnns): ModuleList(
    (0): WeightDropout(
      (module): LSTM(400, 1152, batch_first=True)
    )
    (1): WeightDropout(
      (module): LSTM(1152, 400, batch_first=True)
    )
  )
  (input_dp): RNNDropout()
  (hidden_dps): ModuleList(
    (0): RNNDropout()
    (1): RNNDropout()
  )
)&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AWD_LSTM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vocab_sz&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10_000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;emb_sz&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;400&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_hid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1152&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_layers&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;AWD_LSTM(
  (encoder): Embedding(10000, 400, padding_idx=1)
  (encoder_dp): EmbeddingDropout(
    (emb): Embedding(10000, 400, padding_idx=1)
  )
  (rnns): ModuleList(
    (0): WeightDropout(
      (module): LSTM(400, 1152, batch_first=True)
    )
    (1): WeightDropout(
      (module): LSTM(1152, 1152, batch_first=True)
    )
    (2): WeightDropout(
      (module): LSTM(1152, 1152, batch_first=True)
    )
    (3): WeightDropout(
      (module): LSTM(1152, 1152, batch_first=True)
    )
    (4): WeightDropout(
      (module): LSTM(1152, 400, batch_first=True)
    )
  )
  (input_dp): RNNDropout()
  (hidden_dps): ModuleList(
    (0): RNNDropout()
    (1): RNNDropout()
    (2): RNNDropout()
    (3): RNNDropout()
    (4): RNNDropout()
  )
)&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;We see the first and final layers have similar dimensions in the two examples.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;To summarize:We'll use a 3 layer network with input and output dimensions of (400, 1152), (1152, 1152) and (1152, 400) as in the AWD-LSTM paper. This should be handled automatically by the library.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;nn.LSTM&quot;&gt;nn.LSTM&lt;a class=&quot;anchor-link&quot; href=&quot;#nn.LSTM&quot;&gt; &lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;In the module list above, the layers are actually WeightDropout layers. We can verify this from the hidden constructor method that is called when the RNNs are being created. First, a regular &lt;code&gt;nn.LSTM&lt;/code&gt; layer is created before being passed to the &lt;code&gt;WeightDropout&lt;/code&gt; module.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;_one_rnn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_in&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bidir&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;weight_p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s2&quot;&gt;&amp;quot;Return one of the inner rnn&amp;quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;rnn&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LSTM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_in&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_first&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bidirectional&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bidir&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;WeightDropout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rnn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;weight_p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Lets have a look at an example from the &lt;a href=&quot;https://pytorch.org/docs/stable/nn.html#lstm&quot;&gt;nn.LSTM documentation&lt;/a&gt;, also see &lt;a href=&quot;https://pytorch.org/docs/stable/_modules/torch/nn/modules/rnn.html#LSTM&quot;&gt;source code here&lt;/a&gt;. We'll make a 1 layer LSTM with input size of 10 and hidden size of 20. Note that in the AWD-LSTM case the input size is equal to the embedding size (400 by default).&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inp_s&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# input size&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;hid_s&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# hidden size&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lstm&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LSTM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inp_s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hid_s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_layers&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;The documentation details that the LSTM expects input in the form of &lt;code&gt;input(seq_len, batch, input_size)&lt;/code&gt;. Seq_len is the length of the part of the text the model will see in each iteration (seq_len = 72 by default in fastais language_model_learner, that is 72 tokens). The batch size is the number of documents the models sees in each iteration.&lt;/p&gt;
&lt;p&gt;h0 and c0 are the inital hidden and cell states (set to 0 if not provided). The documentation specifiy their shapes as: &lt;code&gt;(num_layers * num_directions, batch, hidden_size)&lt;/code&gt;.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;16&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;n_l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_d&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# we are testing a 1 layer and 1 direction lstm&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;seq_len&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seq_len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inp_s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;h0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hid_s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;c0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hid_s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;(torch.Size([5, 16, 10]), torch.Size([1, 16, 20]), torch.Size([1, 16, 20]))&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;The output from the LSTM should be a tuple of &lt;code&gt;output, (h_n, c_n)&lt;/code&gt;where output has shape given by: &lt;code&gt;(seq_len, batch, num_directions * hidden_size)&lt;/code&gt;:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lstm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;torch.Size([5, 16, 20])&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Let's also check the actual shape of our weights by looping through the &lt;code&gt;state_dict()&lt;/code&gt;:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lstm&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;state_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lstm&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;state_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keys&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;[(&amp;#39;weight_ih_l0&amp;#39;, torch.Size([80, 10])),
 (&amp;#39;weight_hh_l0&amp;#39;, torch.Size([80, 20])),
 (&amp;#39;bias_ih_l0&amp;#39;, torch.Size([80])),
 (&amp;#39;bias_hh_l0&amp;#39;, torch.Size([80]))]&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Here we recognize the input size of 10 and hidden size of 20, but where does the 80 come from? The documentation specifies that the weights will be of dimension &lt;code&gt;(4*hidden_size, input_size)&lt;/code&gt;. The '4' is called gate_size, and we can find this in the source code for the base RNN module also:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mode&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;LSTM&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;gate_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;blockquote&gt;&lt;p&gt;To summarize:we expect two sets of weights and biases per LSTM: &lt;em&gt; weight_ih_l0 with a shape of (4&lt;/em&gt;hidden_size, input_size)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;weight_hh_l0 with a shape of (4*hidden_size, hidden_size)&lt;/li&gt;
&lt;li&gt;bias_ih_l0 with a shape of (4*hidden_size)&lt;/li&gt;
&lt;li&gt;bias_hh_l0 with a shape of (4*hidden_size)&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;WeightDropout&quot;&gt;WeightDropout&lt;a class=&quot;anchor-link&quot; href=&quot;#WeightDropout&quot;&gt; &lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;We can see from the &lt;code&gt;_one_rnn&lt;/code&gt; that the nn.LSTM is transformed to a WeightDropout module. The &lt;a href=&quot;https://dev.fast.ai/text.models.awdlstm#WeightDropout&quot;&gt;documentation&lt;/a&gt; describes the module as 'A module that warps another layer in which some weights will be replaced by 0 during training'. From the source code we can see that it's the &lt;code&gt;weight_hh_l0&lt;/code&gt; weights that will be modified, and that these weights are duplicated with suffix 'raw' in the WeightDropout module: &lt;code&gt;self.register_parameter(f'{layer}_raw', nn.Parameter(w.data))&lt;/code&gt;.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Let's see if we can verify this by first checking the weights from the lstm from the above section. Of the 80*20 = 1600 weights in the hh_l0 layer, none are 0:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;orig_wts&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;getattr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lstm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;weight_hh_l0&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;orig_wts&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;orig_wts&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;(torch.Size([80, 20]), tensor(0))&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;But if pass the lstm through the WeightDroput module, approximately half of the 1600 weights are set to 0. Note that we have to call the model on the input since the weights are only reset during the forward pass. The weights are also &lt;em&gt;only&lt;/em&gt; reset for the WeighDropout's  internal LSTM module, while a copy with suffix '_raw' retains the original weights.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;wd&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;WeightDropout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lstm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;weight_p&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;wd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# we don&amp;#39;t need the output in this case&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;The &lt;code&gt;.module&lt;/code&gt; attribute of the &lt;code&gt;wd&lt;/code&gt; object is our original LSTM:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;wd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;module&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;LSTM(10, 20)&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;And about half its weights have been set to 0:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;getattr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;wd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;weight_hh_l0&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;tensor(826)&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;The original weights from the lstm matches the '_raw' weights of the WeightDropout module:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_eq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;orig_wts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;getattr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;wd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;weight_hh_l0_raw&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;The new layers are as expected:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;wd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;state_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keys&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;odict_keys([&amp;#39;weight_hh_l0_raw&amp;#39;, &amp;#39;module.weight_ih_l0&amp;#39;, &amp;#39;module.bias_ih_l0&amp;#39;, &amp;#39;module.bias_hh_l0&amp;#39;])&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;RNN-dropout&quot;&gt;RNN dropout&lt;a class=&quot;anchor-link&quot; href=&quot;#RNN-dropout&quot;&gt; &lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Finally several RNNDropout layers are being created - one for the input and one for each LSTM. This dropout is applied to the input embedding and on the output of each LSTM. We can test the functionality with &lt;code&gt;inp&lt;/code&gt; from the above section.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;RNNDropout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dp_out&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;inp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dp_out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;(torch.Size([5, 16, 10]), torch.Size([5, 16, 10]))&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;The documentation also says: 'Dropout with probability p that is consistent on the seq_len dimension.' In our input from the above section, seq_len is the first dimension (index 0), and if we check for items equaling 0 and sum along the second dimension (index 1) we see that the same tokens are dropped out for the entire batch (our sample batch size is 16) consistently in approximately half of the instances.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dp_out&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;tensor([[ 0,  0, 16, 16, 16, 16,  0,  0, 16,  0],
        [ 0, 16, 16, 16, 16,  0,  0, 16, 16,  0],
        [ 0,  0,  0, 16,  0,  0,  0,  0, 16, 16],
        [ 0,  0, 16, 16,  0, 16,  0, 16,  0, 16],
        [ 0, 16,  0, 16,  0, 16, 16,  0, 16, 16]])&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h1 id=&quot;IMDb-inspection&quot;&gt;IMDb inspection&lt;a class=&quot;anchor-link&quot; href=&quot;#IMDb-inspection&quot;&gt; &lt;/a&gt;&lt;/h1&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Let's take a look at a minimal IMDB example from the &lt;a href=&quot;https://dev.fast.ai/tutorial.datablock#Text&quot;&gt;fastai documentation&lt;/a&gt; to verify our understanding of the AWD-LSTM architecture.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;imdb_path&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;untar_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;URLs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;IMDB_SAMPLE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;imdb_path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;texts.csv&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dls&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TextDataLoaders&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;imdb_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;text_col&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;text&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;is_lm&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;valid_col&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;is_valid&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;learn&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;language_model_learner&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dls&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;AWD_LSTM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;


&lt;div class=&quot;output_html rendered_html output_subarea &quot;&gt;

&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;The vocab is of length 7080 and vocab index 1 is 'xxpad':&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dls&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vocab&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dls&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vocab&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;([&amp;#39;xxunk&amp;#39;, &amp;#39;xxpad&amp;#39;, &amp;#39;xxbos&amp;#39;, &amp;#39;xxeos&amp;#39;, &amp;#39;xxfld&amp;#39;], 7080)&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;In our model we recognize &lt;code&gt;Embedding(7080, 400, padding_idx=1)&lt;/code&gt; as vocab_size x embedding size with the correct padding token. We also see that the (input, output) dimensions of our LSTM-layers are as expected, and with the expected dropout layers added.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;SequentialRNN(
  (0): AWD_LSTM(
    (encoder): Embedding(7080, 400, padding_idx=1)
    (encoder_dp): EmbeddingDropout(
      (emb): Embedding(7080, 400, padding_idx=1)
    )
    (rnns): ModuleList(
      (0): WeightDropout(
        (module): LSTM(400, 1152, batch_first=True)
      )
      (1): WeightDropout(
        (module): LSTM(1152, 1152, batch_first=True)
      )
      (2): WeightDropout(
        (module): LSTM(1152, 400, batch_first=True)
      )
    )
    (input_dp): RNNDropout()
    (hidden_dps): ModuleList(
      (0): RNNDropout()
      (1): RNNDropout()
      (2): RNNDropout()
    )
  )
  (1): LinearDecoder(
    (decoder): Linear(in_features=400, out_features=7080, bias=True)
    (output_dp): RNNDropout()
  )
)&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;The model summary shows us the default batch size of 64 and seq_len of 72.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;summary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;SequentialRNN (Input shape: [&amp;#39;64 x 72&amp;#39;])
================================================================
Layer (type)         Output Shape         Param #    Trainable 
================================================================
RNNDropout           64 x 72 x 400        0          False     
________________________________________________________________
RNNDropout           64 x 72 x 1152       0          False     
________________________________________________________________
RNNDropout           64 x 72 x 1152       0          False     
________________________________________________________________
Linear               64 x 72 x 7080       2,839,080  True      
________________________________________________________________
RNNDropout           64 x 72 x 400        0          False     
________________________________________________________________

Total params: 2,839,080
Total trainable params: 2,839,080
Total non-trainable params: 0

Optimizer used: &amp;lt;function Adam at 0x7fa03d7cbdd0&amp;gt;
Loss function: FlattenedLoss of CrossEntropyLoss()

Model frozen up to parameter group number 3

Callbacks:
  - TrainEvalCallback
  - Recorder
  - ProgressCallback
  - ModelReseter
  - RNNRegularizer&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;And finally, the layer names and shapes also is consistent with a gate size of 4 (1152*4 = 4608). Note the enumeration of the layers: &lt;strong&gt;0.&lt;/strong&gt; is the encoder part of the architecture (including the embedding called encoder) and &lt;strong&gt;1.&lt;/strong&gt; is the decoder.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;state_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keys&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;nb&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\t&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;state_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;

&lt;div class=&quot;output_subarea output_stream output_stdout output_text&quot;&gt;
&lt;pre&gt;0.encoder.weight 	 torch.Size([7080, 400])
0.encoder_dp.emb.weight 	 torch.Size([7080, 400])
0.rnns.0.weight_hh_l0_raw 	 torch.Size([4608, 1152])
0.rnns.0.module.weight_ih_l0 	 torch.Size([4608, 400])
0.rnns.0.module.bias_ih_l0 	 torch.Size([4608])
0.rnns.0.module.bias_hh_l0 	 torch.Size([4608])
0.rnns.1.weight_hh_l0_raw 	 torch.Size([4608, 1152])
0.rnns.1.module.weight_ih_l0 	 torch.Size([4608, 1152])
0.rnns.1.module.bias_ih_l0 	 torch.Size([4608])
0.rnns.1.module.bias_hh_l0 	 torch.Size([4608])
0.rnns.2.weight_hh_l0_raw 	 torch.Size([1600, 400])
0.rnns.2.module.weight_ih_l0 	 torch.Size([1600, 1152])
0.rnns.2.module.bias_ih_l0 	 torch.Size([1600])
0.rnns.2.module.bias_hh_l0 	 torch.Size([1600])
1.decoder.weight 	 torch.Size([7080, 400])
1.decoder.bias 	 torch.Size([7080])
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;/div&gt;</content><author><name></name></author><summary type="html"></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://hallvagi.github.io/dl-explorer/images/some_folder/your_image.png" /><media:content medium="image" url="https://hallvagi.github.io/dl-explorer/images/some_folder/your_image.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Finding a Norwegian language dataset for sentiment analysis</title><link href="https://hallvagi.github.io/dl-explorer/nlp/fastai/2020/04/06/get-data.html" rel="alternate" type="text/html" title="Finding a Norwegian language dataset for sentiment analysis" /><published>2020-04-06T00:00:00-05:00</published><updated>2020-04-06T00:00:00-05:00</updated><id>https://hallvagi.github.io/dl-explorer/nlp/fastai/2020/04/06/get-data</id><content type="html" xml:base="https://hallvagi.github.io/dl-explorer/nlp/fastai/2020/04/06/get-data.html">&lt;!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-04-06-get-data.ipynb
--&gt;

&lt;div class=&quot;container&quot; id=&quot;notebook-container&quot;&gt;
        
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;I'm currently taking the fast.ai online course practical deep learning for coders (to be released publicly in July 2020). As part of the studies I want to explore the fastai2 deep learning library. I will do so by testing various NLP methods.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Over the next few posts I'll got through the entire process of finding and processing data, training various models and also interpret the results. I'll try to highlight the various things I've been struggling with or confused about. I think writing short blog posts such as these are a great way of learning new material.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;The-NOREC-dataset&quot;&gt;The NOREC dataset&lt;a class=&quot;anchor-link&quot; href=&quot;#The-NOREC-dataset&quot;&gt; &lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;I wanted to find a dataset in my native Norwegian to analyze. NLP for languages other than English is often challenging, even though many new techniques are addressing this. After a bit of searching I found the &lt;a href=&quot;https://github.com/ltgoslo/norec&quot;&gt;Norec dataset&lt;/a&gt;. It contains Norwegian language reviews of various films, music etc. The dataset even comes with a &lt;a href=&quot;http://www.lrec-conf.org/proceedings/lrec2018/pdf/851.pdf&quot;&gt;paper&lt;/a&gt; that explains the setup of the data! This seems like a great case study, and is similar to the IMDB movie review sentiment analyses, which is one of the built in datasets of the fastai2 library.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;The repo includes a utility library and a download.sh script. This is what you normally would want to use to ease the process of actually getting the data, but in this case I would like to do things manually. We'll be using the fastai2 library (which upon release will be renamed to fastai).&lt;/p&gt;
&lt;p&gt;Note that &lt;code&gt;import *&lt;/code&gt; is usually not encouraged, but the fastai2 library has defined it's __all__ variables properly, so this won't be a problem. See &lt;a href=&quot;https://github.com/fastai/fastai2/blob/master/fastai2/imports.py&quot;&gt;this file&lt;/a&gt; for the various imports that is part of the library.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;fastai2.text.all&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;I'm using fastai2 '0.0.17' and fastcore '0.1.17'. To check the version you can uncomment the following lines:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;details class=&quot;description&quot;&gt;
      &lt;summary class=&quot;btn btn-sm&quot; data-open=&quot;Hide Code&quot; data-close=&quot;Show Code&quot;&gt;&lt;/summary&gt;
        &lt;p&gt;&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#collapse&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# import fastai2, fastcore&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# fastai2.__version__, fastcore.__version__&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
    &lt;/details&gt;
&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;First we'll download and extract the data from the &lt;code&gt;url&lt;/code&gt; given in the download.sh file in the github-repo to a &lt;code&gt;dest&lt;/code&gt; with &lt;code&gt;archive_name&lt;/code&gt;. Note the &lt;code&gt;!command&lt;/code&gt; syntax which runs the corresponding wget shell command. The wget command only has to be run once.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;url&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;http://folk.uio.no/eivinabe/norec-1.0.1.tar.gz&amp;#39;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;data_path&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;~/.fastai&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dest&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data_path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;archive&amp;#39;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;archive_name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;norec.tar.gz&amp;#39;&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;wget &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;url&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; -O &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;dest/archive_name&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; -q
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Then we'll extract the archive with the tarfile library (imported via the fastai2 import at the beginning of the notebook). We'll extract from the archive location to &lt;code&gt;data&lt;/code&gt;. Finally we set a new &lt;code&gt;path&lt;/code&gt; that points to this location.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tarfile&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dest&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;archive_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;extractall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data_path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;data&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data_path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;data/norec&amp;#39;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;BASE_PATH&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# this avoids printing the entire file-path when we list files in a directory&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ls&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;(#4) [Path(&amp;#39;metadata.json&amp;#39;),Path(&amp;#39;conllu.tar.gz&amp;#39;),Path(&amp;#39;html.tar.gz&amp;#39;),Path(&amp;#39;README.txt&amp;#39;)]&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;The archive contains a .json file with metadata, and among other, a html.tar.gz archive with our desired raw texts. We'll 
extract this archive too. The conllu.tar.gz contains tokenized and filtered text, and we don't need this for the time being.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tarfile&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;html.tar.gz&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;extractall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ls&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;(#5) [Path(&amp;#39;metadata.json&amp;#39;),Path(&amp;#39;conllu.tar.gz&amp;#39;),Path(&amp;#39;html.tar.gz&amp;#39;),Path(&amp;#39;html&amp;#39;),Path(&amp;#39;README.txt&amp;#39;)]&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;The extracted archive is now in the &lt;code&gt;data/norec/html&lt;/code&gt; folder, which contains the train, dev (we'll call it validation) and test split.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;html&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ls&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;(#3) [Path(&amp;#39;html/train&amp;#39;),Path(&amp;#39;html/test&amp;#39;),Path(&amp;#39;html/dev&amp;#39;)]&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Inspect-the-metadata&quot;&gt;Inspect the metadata&lt;a class=&quot;anchor-link&quot; href=&quot;#Inspect-the-metadata&quot;&gt; &lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Let's inspect the metatdata file and see if we are able to make sense of the data. But what does this json file look like? We can use the &lt;code&gt;head&lt;/code&gt; command to have a look at the raw file contents before we attempt to read it into a pandas dataframe:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;head -n &lt;span class=&quot;m&quot;&gt;20&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;path/&lt;span class=&quot;s1&quot;&gt;&amp;#39;metadata.json&amp;#39;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;

&lt;div class=&quot;output_subarea output_stream output_stdout output_text&quot;&gt;
&lt;pre&gt;{
  &amp;#34;000000&amp;#34;: {
    &amp;#34;authors&amp;#34;: [
      &amp;#34;Birger Vestmo&amp;#34;
    ],
    &amp;#34;category&amp;#34;: &amp;#34;screen&amp;#34;,
    &amp;#34;day&amp;#34;: 27,
    &amp;#34;excerpt&amp;#34;: &amp;#34;Toppen innen tv-drama akkurat nå!&amp;#34;,
    &amp;#34;id&amp;#34;: 0,
    &amp;#34;language&amp;#34;: &amp;#34;nb&amp;#34;,
    &amp;#34;month&amp;#34;: 9,
    &amp;#34;rating&amp;#34;: 6,
    &amp;#34;source&amp;#34;: &amp;#34;p3&amp;#34;,
    &amp;#34;source-category&amp;#34;: &amp;#34;tv&amp;#34;,
    &amp;#34;source-id&amp;#34;: 74781,
    &amp;#34;source-tags&amp;#34;: [],
    &amp;#34;split&amp;#34;: &amp;#34;train&amp;#34;,
    &amp;#34;tags&amp;#34;: [
      &amp;#34;tv&amp;#34;
    ],
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Let's try to read the data with pandas default &lt;code&gt;read_json()&lt;/code&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_json&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;metadata.json&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;


&lt;div class=&quot;output_html rendered_html output_subarea output_execute_result&quot;&gt;
&lt;div&gt;
&lt;style scoped=&quot;&quot;&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&quot;1&quot; class=&quot;dataframe&quot;&gt;
  &lt;thead&gt;
    &lt;tr style=&quot;text-align: right;&quot;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;th&gt;5&lt;/th&gt;
      &lt;th&gt;6&lt;/th&gt;
      &lt;th&gt;7&lt;/th&gt;
      &lt;th&gt;8&lt;/th&gt;
      &lt;th&gt;9&lt;/th&gt;
      &lt;th&gt;...&lt;/th&gt;
      &lt;th&gt;705136&lt;/th&gt;
      &lt;th&gt;705137&lt;/th&gt;
      &lt;th&gt;705138&lt;/th&gt;
      &lt;th&gt;705139&lt;/th&gt;
      &lt;th&gt;705140&lt;/th&gt;
      &lt;th&gt;705141&lt;/th&gt;
      &lt;th&gt;705142&lt;/th&gt;
      &lt;th&gt;705143&lt;/th&gt;
      &lt;th&gt;705144&lt;/th&gt;
      &lt;th&gt;705145&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;authors&lt;/th&gt;
      &lt;td&gt;[Birger Vestmo]&lt;/td&gt;
      &lt;td&gt;[Birger Vestmo]&lt;/td&gt;
      &lt;td&gt;[Birger Vestmo]&lt;/td&gt;
      &lt;td&gt;[Birger Vestmo]&lt;/td&gt;
      &lt;td&gt;[Birger Vestmo]&lt;/td&gt;
      &lt;td&gt;[Torfinn Borkhus]&lt;/td&gt;
      &lt;td&gt;[Torfinn Borkhus]&lt;/td&gt;
      &lt;td&gt;[Torfinn Borkhus]&lt;/td&gt;
      &lt;td&gt;[Torfinn Borkhus]&lt;/td&gt;
      &lt;td&gt;[Torfinn Borkhus]&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;[Arnfinn Bø-Rygg]&lt;/td&gt;
      &lt;td&gt;[Leif Tore Lindø]&lt;/td&gt;
      &lt;td&gt;[Leif Tore Lindø]&lt;/td&gt;
      &lt;td&gt;[Kine Hult]&lt;/td&gt;
      &lt;td&gt;[Arnfinn Bø-Rygg]&lt;/td&gt;
      &lt;td&gt;[Leif Tore Lindø]&lt;/td&gt;
      &lt;td&gt;[Arnfinn Bø-Rygg]&lt;/td&gt;
      &lt;td&gt;[Leif Tore Lindø]&lt;/td&gt;
      &lt;td&gt;[Leif Tore Lindø]&lt;/td&gt;
      &lt;td&gt;[Elisabeth Bie]&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;category&lt;/th&gt;
      &lt;td&gt;screen&lt;/td&gt;
      &lt;td&gt;screen&lt;/td&gt;
      &lt;td&gt;screen&lt;/td&gt;
      &lt;td&gt;screen&lt;/td&gt;
      &lt;td&gt;screen&lt;/td&gt;
      &lt;td&gt;screen&lt;/td&gt;
      &lt;td&gt;screen&lt;/td&gt;
      &lt;td&gt;screen&lt;/td&gt;
      &lt;td&gt;screen&lt;/td&gt;
      &lt;td&gt;screen&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;music&lt;/td&gt;
      &lt;td&gt;music&lt;/td&gt;
      &lt;td&gt;music&lt;/td&gt;
      &lt;td&gt;music&lt;/td&gt;
      &lt;td&gt;music&lt;/td&gt;
      &lt;td&gt;music&lt;/td&gt;
      &lt;td&gt;music&lt;/td&gt;
      &lt;td&gt;music&lt;/td&gt;
      &lt;td&gt;music&lt;/td&gt;
      &lt;td&gt;music&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;day&lt;/th&gt;
      &lt;td&gt;27&lt;/td&gt;
      &lt;td&gt;22&lt;/td&gt;
      &lt;td&gt;22&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;9&lt;/td&gt;
      &lt;td&gt;25&lt;/td&gt;
      &lt;td&gt;25&lt;/td&gt;
      &lt;td&gt;26&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;8&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;8&lt;/td&gt;
      &lt;td&gt;16&lt;/td&gt;
      &lt;td&gt;13&lt;/td&gt;
      &lt;td&gt;13&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;8&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;17&lt;/td&gt;
      &lt;td&gt;25&lt;/td&gt;
      &lt;td&gt;9&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;3 rows × 35189 columns&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Not quite what we looked for! From the read_json documentation we see that we can change the orientation of the data with the &lt;code&gt;orient&lt;/code&gt;option. 'index' seems to be what we look for. Note that we also could have transposed the data frame for a similar result.&lt;/p&gt;
&lt;p&gt;There is another problem that is harder to spot: The index of our dataframe should be the string representation of the json key. This is the actual file name of the corresponding review, but it is cast to an &lt;code&gt;int&lt;/code&gt;. This turns '000000' into 0. So we'll set &lt;code&gt;convert_axes&lt;/code&gt; to &lt;code&gt;False&lt;/code&gt;. We'll also reset the index and rename it to &lt;code&gt;filename&lt;/code&gt;.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_json&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;metadata.json&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;orient&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;index&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;convert_axes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reset_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;columns&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;index&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;filename&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;


&lt;div class=&quot;output_html rendered_html output_subarea output_execute_result&quot;&gt;
&lt;div&gt;
&lt;style scoped=&quot;&quot;&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&quot;1&quot; class=&quot;dataframe&quot;&gt;
  &lt;thead&gt;
    &lt;tr style=&quot;text-align: right;&quot;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;filename&lt;/th&gt;
      &lt;th&gt;authors&lt;/th&gt;
      &lt;th&gt;category&lt;/th&gt;
      &lt;th&gt;day&lt;/th&gt;
      &lt;th&gt;excerpt&lt;/th&gt;
      &lt;th&gt;id&lt;/th&gt;
      &lt;th&gt;language&lt;/th&gt;
      &lt;th&gt;month&lt;/th&gt;
      &lt;th&gt;rating&lt;/th&gt;
      &lt;th&gt;source&lt;/th&gt;
      &lt;th&gt;source-category&lt;/th&gt;
      &lt;th&gt;source-id&lt;/th&gt;
      &lt;th&gt;source-tags&lt;/th&gt;
      &lt;th&gt;split&lt;/th&gt;
      &lt;th&gt;tags&lt;/th&gt;
      &lt;th&gt;title&lt;/th&gt;
      &lt;th&gt;url&lt;/th&gt;
      &lt;th&gt;year&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;000000&lt;/td&gt;
      &lt;td&gt;[Birger Vestmo]&lt;/td&gt;
      &lt;td&gt;screen&lt;/td&gt;
      &lt;td&gt;27&lt;/td&gt;
      &lt;td&gt;Toppen innen tv-drama akkurat nå!&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;nb&lt;/td&gt;
      &lt;td&gt;9&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;p3&lt;/td&gt;
      &lt;td&gt;tv&lt;/td&gt;
      &lt;td&gt;74781&lt;/td&gt;
      &lt;td&gt;[]&lt;/td&gt;
      &lt;td&gt;train&lt;/td&gt;
      &lt;td&gt;[tv]&lt;/td&gt;
      &lt;td&gt;Rome S02&lt;/td&gt;
      &lt;td&gt;http://p3.no/filmpolitiet/rome-02&lt;/td&gt;
      &lt;td&gt;2007&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;000001&lt;/td&gt;
      &lt;td&gt;[Birger Vestmo]&lt;/td&gt;
      &lt;td&gt;screen&lt;/td&gt;
      &lt;td&gt;22&lt;/td&gt;
      &lt;td&gt;Gull for &amp;lt;em&amp;gt;Twin Peaks&amp;lt;/em&amp;gt;-fans!&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;nb&lt;/td&gt;
      &lt;td&gt;11&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;p3&lt;/td&gt;
      &lt;td&gt;tv&lt;/td&gt;
      &lt;td&gt;74065&lt;/td&gt;
      &lt;td&gt;[]&lt;/td&gt;
      &lt;td&gt;train&lt;/td&gt;
      &lt;td&gt;[tv]&lt;/td&gt;
      &lt;td&gt;Twin Peaks - definitive gold box edition&lt;/td&gt;
      &lt;td&gt;http://p3.no/filmpolitiet/twin-peaks-definitive-gold-box-edition&lt;/td&gt;
      &lt;td&gt;2007&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;000002&lt;/td&gt;
      &lt;td&gt;[Birger Vestmo]&lt;/td&gt;
      &lt;td&gt;screen&lt;/td&gt;
      &lt;td&gt;22&lt;/td&gt;
      &lt;td&gt;The Wire vil gjøre deg avhengig, men på en god måte.&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;nb&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;p3&lt;/td&gt;
      &lt;td&gt;tv&lt;/td&gt;
      &lt;td&gt;73886&lt;/td&gt;
      &lt;td&gt;[]&lt;/td&gt;
      &lt;td&gt;train&lt;/td&gt;
      &lt;td&gt;[tv]&lt;/td&gt;
      &lt;td&gt;The Wire (sesong 1-4)&lt;/td&gt;
      &lt;td&gt;http://p3.no/filmpolitiet/the-wire-sesong-1-4&lt;/td&gt;
      &lt;td&gt;2008&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;There are several category-like columns as explained in the paper. We will use the &lt;code&gt;category&lt;/code&gt; column.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;category&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value_counts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;screen         13085
music          12410
literature      3526
products        3120
games           1765
restaurants      534
stage            530
sports           117
misc             102
Name: category, dtype: int64&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;I'm also curious about the distribution of &lt;a href=&quot;https://en.wikipedia.org/wiki/Bokm%C3%A5l&quot;&gt;bokmål&lt;/a&gt; (nb) vs &lt;a href=&quot;https://en.wikipedia.org/wiki/Nynorsk&quot;&gt;nynorsk&lt;/a&gt; (nn). It seems the vast majority of reviews are in bokmål.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;language&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value_counts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;nb    34656
nn      533
Name: language, dtype: int64&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Get-a-subset-of-the-data&quot;&gt;Get a subset of the data&lt;a class=&quot;anchor-link&quot; href=&quot;#Get-a-subset-of-the-data&quot;&gt; &lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;We'll proceed with a subset of the data. We'll look at the &lt;strong&gt;screen&lt;/strong&gt; sub category and &lt;strong&gt;bokmål&lt;/strong&gt; (nb) language. The screen category contains both movie and TV-reviews. The data frame also contains several columns we won't be using now so let's select the relevant columns. We're left with ~ 13000 reviews.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;screen&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;category&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;screen&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;language&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;nb&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;screen&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;screen&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;filename&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;rating&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;title&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;split&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;screen&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;screen&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;

&lt;div class=&quot;output_subarea output_stream output_stdout output_text&quot;&gt;
&lt;pre&gt;(12924, 4)
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_area&quot;&gt;


&lt;div class=&quot;output_html rendered_html output_subarea output_execute_result&quot;&gt;
&lt;div&gt;
&lt;style scoped=&quot;&quot;&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&quot;1&quot; class=&quot;dataframe&quot;&gt;
  &lt;thead&gt;
    &lt;tr style=&quot;text-align: right;&quot;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;filename&lt;/th&gt;
      &lt;th&gt;rating&lt;/th&gt;
      &lt;th&gt;title&lt;/th&gt;
      &lt;th&gt;split&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;000000&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;Rome S02&lt;/td&gt;
      &lt;td&gt;train&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;000001&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;Twin Peaks - definitive gold box edition&lt;/td&gt;
      &lt;td&gt;train&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;000002&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;The Wire (sesong 1-4)&lt;/td&gt;
      &lt;td&gt;train&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Let's also change the filename so that is gives the path to our review files.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;screen&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;filename&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;html/&amp;#39;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;screen&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;split&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;/&amp;#39;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;screen&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;filename&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;.html&amp;#39;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;screen&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sample&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;


&lt;div class=&quot;output_html rendered_html output_subarea output_execute_result&quot;&gt;
&lt;div&gt;
&lt;style scoped=&quot;&quot;&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&quot;1&quot; class=&quot;dataframe&quot;&gt;
  &lt;thead&gt;
    &lt;tr style=&quot;text-align: right;&quot;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;filename&lt;/th&gt;
      &lt;th&gt;rating&lt;/th&gt;
      &lt;th&gt;title&lt;/th&gt;
      &lt;th&gt;split&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;21438&lt;/th&gt;
      &lt;td&gt;html/train/301590.html&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;På den smale sykkelsti&lt;/td&gt;
      &lt;td&gt;train&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;28588&lt;/th&gt;
      &lt;td&gt;html/train/600841.html&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;Lykken er en olivenlund&lt;/td&gt;
      &lt;td&gt;train&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;32395&lt;/th&gt;
      &lt;td&gt;html/test/702352.html&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;Sterk, sanselig skjønnhet fra Aldomóvar&lt;/td&gt;
      &lt;td&gt;test&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;The ratings of the screen category has a slight positive skew.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;screen&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;rating&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value_counts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sort_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;bar&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_png output_subarea &quot;&gt;
&lt;img src=&quot;data:image/png;base64,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
&quot; /&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;We'll encode a rating of 1 to 3 as negative, and 5 and 6 as positive. Reviews rated 4 will be removed. We'll lose a bit of data this way, but this means that the positive and negative review are a bit more distinct, and will make down stream classification a bit simpler. This leaves us with ~8600 reviews.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;screen&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;screen&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;screen&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;rating&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reset_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;drop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;screen&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;sentiment&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;screen&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;rating&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;apply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;positive&amp;#39;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;negative&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;screen&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;screen&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;

&lt;div class=&quot;output_subarea output_stream output_stdout output_text&quot;&gt;
&lt;pre&gt;(8613, 5)
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_area&quot;&gt;


&lt;div class=&quot;output_html rendered_html output_subarea output_execute_result&quot;&gt;
&lt;div&gt;
&lt;style scoped=&quot;&quot;&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&quot;1&quot; class=&quot;dataframe&quot;&gt;
  &lt;thead&gt;
    &lt;tr style=&quot;text-align: right;&quot;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;filename&lt;/th&gt;
      &lt;th&gt;rating&lt;/th&gt;
      &lt;th&gt;title&lt;/th&gt;
      &lt;th&gt;split&lt;/th&gt;
      &lt;th&gt;sentiment&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;html/train/000000.html&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;Rome S02&lt;/td&gt;
      &lt;td&gt;train&lt;/td&gt;
      &lt;td&gt;positive&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;html/train/000001.html&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;Twin Peaks - definitive gold box edition&lt;/td&gt;
      &lt;td&gt;train&lt;/td&gt;
      &lt;td&gt;positive&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;html/train/000002.html&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;The Wire (sesong 1-4)&lt;/td&gt;
      &lt;td&gt;train&lt;/td&gt;
      &lt;td&gt;positive&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;The train, validation (dev) and test split is ok:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;screen&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;split&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value_counts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;normalize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;train    0.803321
dev      0.101707
test     0.094973
Name: split, dtype: float64&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;And the dataset is well balanced, i.e. similar amount of labels for each class.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;screen&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;sentiment&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value_counts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;normalize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;negative    0.512713
positive    0.487287
Name: sentiment, dtype: float64&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Add-text-to-the-data-frame&quot;&gt;Add text to the data frame&lt;a class=&quot;anchor-link&quot; href=&quot;#Add-text-to-the-data-frame&quot;&gt; &lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Let's also add the full text to the dataframe for convenience. This step is not strictly necessary, and doesn't scale to big data. The &lt;code&gt;html/train&lt;/code&gt; folder contains html files, and the data frame gives us our filenames.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;html/train&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ls&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;(#28158) [Path(&amp;#39;html/train/201232.html&amp;#39;),Path(&amp;#39;html/train/601043.html&amp;#39;),Path(&amp;#39;html/train/108030.html&amp;#39;),Path(&amp;#39;html/train/700390.html&amp;#39;),Path(&amp;#39;html/train/702069.html&amp;#39;),Path(&amp;#39;html/train/100023.html&amp;#39;),Path(&amp;#39;html/train/701430.html&amp;#39;),Path(&amp;#39;html/train/201765.html&amp;#39;),Path(&amp;#39;html/train/302012.html&amp;#39;),Path(&amp;#39;html/train/400836.html&amp;#39;)...]&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;screen&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;


&lt;div class=&quot;output_html rendered_html output_subarea output_execute_result&quot;&gt;
&lt;div&gt;
&lt;style scoped=&quot;&quot;&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&quot;1&quot; class=&quot;dataframe&quot;&gt;
  &lt;thead&gt;
    &lt;tr style=&quot;text-align: right;&quot;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;filename&lt;/th&gt;
      &lt;th&gt;rating&lt;/th&gt;
      &lt;th&gt;title&lt;/th&gt;
      &lt;th&gt;split&lt;/th&gt;
      &lt;th&gt;sentiment&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;html/train/000000.html&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;Rome S02&lt;/td&gt;
      &lt;td&gt;train&lt;/td&gt;
      &lt;td&gt;positive&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;html/train/000001.html&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;Twin Peaks - definitive gold box edition&lt;/td&gt;
      &lt;td&gt;train&lt;/td&gt;
      &lt;td&gt;positive&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;html/train/000002.html&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;The Wire (sesong 1-4)&lt;/td&gt;
      &lt;td&gt;train&lt;/td&gt;
      &lt;td&gt;positive&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Let's inspect the second file in the data frame. We expect it should be a review of Twin Peaks. We'll open the file and print the raw contents.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fn&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;screen&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;filename&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;Path(&amp;#39;html/train/000001.html&amp;#39;)&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;review&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;review&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1500&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;&amp;#39;&amp;lt;h1&amp;gt;Twin Peaks - definitive gold box edition&amp;lt;/h1&amp;gt;\n\n&amp;lt;p&amp;gt;Tv-serien &amp;lt;em&amp;gt;Twin Peaks&amp;lt;/em&amp;gt;, skapt av David Lynch og Mark Frost, trollbandt publikum på starten av 1990-tallet. Nå er begge sesongene samlet på DVD i en såkalt ”definitive gold box edition” som viser at serien ikke har mistet noe av appellen.&amp;lt;/p&amp;gt;\n\n&amp;lt;p&amp;gt;Det eneste som egentlig røper alderen, er at serien ikke er i widescreen, og at flere av skuespillerne fremdeles er unge og vakre. 17 år etter premieren har de falmet, som mennesker gjør, men &amp;lt;em&amp;gt;Twin Peaks&amp;lt;/em&amp;gt; sikrer dem evig liv.&amp;lt;/p&amp;gt;\n\n&amp;lt;h5&amp;gt;Mørke hemmeligheter&amp;lt;/h5&amp;gt;\n\n&amp;lt;p&amp;gt;Serien handler om et mordmysterium i den lille byen &amp;lt;em&amp;gt;Twin Peaks&amp;lt;/em&amp;gt;, et sted langs USAs grense til Canada. Unge, vakre Laura Palmer blir funnet drept, og FBI-etterforsker Dale Cooper kommer til byen for å oppklare saken.&amp;lt;/p&amp;gt;\n\n&amp;lt;p&amp;gt;Her blir han betatt av det tilsynelatende enkle livet i den lille byen mellom den endeløse skogen og de høye fjellene. Men han oppdager også at byen skjuler mørke, farlige hemmeligheter.&amp;lt;/p&amp;gt;\n\n&amp;lt;REMOVE&amp;gt;&amp;lt;small&amp;gt;Anmeldelsen fortsetter under bildet.&amp;lt;/small&amp;gt;&amp;lt;/REMOVE&amp;gt;\n\n&amp;lt;REMOVE&amp;gt;[caption id=&amp;#34;attachment_207347&amp;#34; align=&amp;#34;alignnone&amp;#34; width=&amp;#34;750&amp;#34;]&amp;lt;a href=&amp;#34;http://p3.no/filmpolitiet/wp-content/uploads/2015/01/twinpeaks.jpg&amp;#34;&amp;gt;&amp;lt;img src=&amp;#34;http://p3.no/filmpolitiet/wp-content/uploads/2015/01/twinpeaks-750x421.jpg&amp;#34; alt=&amp;#34;Kyle MacLachlan som Dale Cooper og Sherilyn Fenn som Audrey Horne i Twin Peaks. (Foto: Lynch/Frost Productions)&amp;#34; width=&amp;#34;750&amp;#34; height=&amp;#34;421&amp;#34; class=&amp;#34;size-medium wp-image-207347&amp;#34; /&amp;gt;&amp;lt;/a&amp;gt; Kyle Mac&amp;#39;&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;The data contains normal text but also several html-tags. The REMOVE tag was added by the authors of the dataset to tag unwanted text such as image captions. In general we want to keep our text as intact as possible, but some text is clearly noise. So we'll proceed to get rid of the REMOVE tags and titles. The norec &lt;a href=&quot;https://github.com/ltgoslo/norec/blob/master/src/norec/main.py&quot;&gt;repo&lt;/a&gt; contains a method to do this with the lxml library. We'll change the code slightly to also remove headers.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;lxml.html&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fragments_fromstring&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;html_to_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;html&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt; 
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39; &amp;#39;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;elem&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text_content&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;elem&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fragments_fromstring&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;html&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;elem&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tag&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;p&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;html_to_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;review&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1500&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;&amp;#39;Tv-serien Twin Peaks, skapt av David Lynch og Mark Frost, trollbandt publikum på starten av 1990-tallet. Nå er begge sesongene samlet på DVD i en såkalt ”definitive gold box edition” som viser at serien ikke har mistet noe av appellen. Det eneste som egentlig røper alderen, er at serien ikke er i widescreen, og at flere av skuespillerne fremdeles er unge og vakre. 17 år etter premieren har de falmet, som mennesker gjør, men Twin Peaks sikrer dem evig liv. Serien handler om et mordmysterium i den lille byen Twin Peaks, et sted langs USAs grense til Canada. Unge, vakre Laura Palmer blir funnet drept, og FBI-etterforsker Dale Cooper kommer til byen for å oppklare saken. Her blir han betatt av det tilsynelatende enkle livet i den lille byen mellom den endeløse skogen og de høye fjellene. Men han oppdager også at byen skjuler mørke, farlige hemmeligheter. Twin Peaks holder seg overraskende godt. Historien glir nok litt ut i det absurde i sesong 2, mens sesong 1 er en udiskutabel klassiker. Serien kjører en tilnærmet tidløs stil som idoliserer 50-talls-looken som David Lynch også dyrket i filmen ”Wild at heart” fra samme periode. Handlingen er fremdeles mørk og truende, samtidig som den har en merkelig form for humor, som regel fortalt gjennom Dale Cooper, glimrende spilt av en opplagt Kyle MacLachlan. Twin Peaks har et omfattende galleri av merkelige figurer. Men de er klart definerte, og spenner over et vidt spekter, fra søte Donna, til mystiske Log Lady til yppige Audrey Horn. F&amp;#39;&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;That looks much better! Now lets combine the two methods to make a function to easily get html reviews from a file name&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;get_review&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; 
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;html_to_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_review&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1500&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;&amp;#39;Tv-serien Twin Peaks, skapt av David Lynch og Mark Frost, trollbandt publikum på starten av 1990-tallet. Nå er begge sesongene samlet på DVD i en såkalt ”definitive gold box edition” som viser at serien ikke har mistet noe av appellen. Det eneste som egentlig røper alderen, er at serien ikke er i widescreen, og at flere av skuespillerne fremdeles er unge og vakre. 17 år etter premieren har de falmet, som mennesker gjør, men Twin Peaks sikrer dem evig liv. Serien handler om et mordmysterium i den lille byen Twin Peaks, et sted langs USAs grense til Canada. Unge, vakre Laura Palmer blir funnet drept, og FBI-etterforsker Dale Cooper kommer til byen for å oppklare saken. Her blir han betatt av det tilsynelatende enkle livet i den lille byen mellom den endeløse skogen og de høye fjellene. Men han oppdager også at byen skjuler mørke, farlige hemmeligheter. Twin Peaks holder seg overraskende godt. Historien glir nok litt ut i det absurde i sesong 2, mens sesong 1 er en udiskutabel klassiker. Serien kjører en tilnærmet tidløs stil som idoliserer 50-talls-looken som David Lynch også dyrket i filmen ”Wild at heart” fra samme periode. Handlingen er fremdeles mørk og truende, samtidig som den har en merkelig form for humor, som regel fortalt gjennom Dale Cooper, glimrende spilt av en opplagt Kyle MacLachlan. Twin Peaks har et omfattende galleri av merkelige figurer. Men de er klart definerte, og spenner over et vidt spekter, fra søte Donna, til mystiske Log Lady til yppige Audrey Horn. F&amp;#39;&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Finally we append the review text to our data frame, and save it for future use.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;screen&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;text&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;screen&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;filename&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;apply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;get_review&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;screen&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to_feather&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;norec_df&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;screen&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;


&lt;div class=&quot;output_html rendered_html output_subarea output_execute_result&quot;&gt;
&lt;div&gt;
&lt;style scoped=&quot;&quot;&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&quot;1&quot; class=&quot;dataframe&quot;&gt;
  &lt;thead&gt;
    &lt;tr style=&quot;text-align: right;&quot;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;filename&lt;/th&gt;
      &lt;th&gt;rating&lt;/th&gt;
      &lt;th&gt;title&lt;/th&gt;
      &lt;th&gt;split&lt;/th&gt;
      &lt;th&gt;sentiment&lt;/th&gt;
      &lt;th&gt;text&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;html/train/000000.html&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;Rome S02&lt;/td&gt;
      &lt;td&gt;train&lt;/td&gt;
      &lt;td&gt;positive&lt;/td&gt;
      &lt;td&gt;Den andre og siste sesongen av Rome er ute på DVD i Norge. Om du så sesong 1, vet du at du har noe stort i vente. Har du aldri sett Rome før, stikk ut og kjøp begge sesongene. Dette er nemlig en av verdens beste tv-serier, og etter å ha sett de fire første episodene av sesong 2, konstaterer jeg at kvaliteten ser ut til å holde seg på et nesten overraskende høyt nivå! Sesong 2 starter nøyaktig der sesong 1 sluttet. Julius Cæsar ligger myrdet i Senatet og Lucius Vorenus hulker over liket av Neobie. Så blir historien enda mørkere. Marcus Antonius tar over styringen av Roma, men utfordres fra ...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;html/train/000001.html&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;Twin Peaks - definitive gold box edition&lt;/td&gt;
      &lt;td&gt;train&lt;/td&gt;
      &lt;td&gt;positive&lt;/td&gt;
      &lt;td&gt;Tv-serien Twin Peaks, skapt av David Lynch og Mark Frost, trollbandt publikum på starten av 1990-tallet. Nå er begge sesongene samlet på DVD i en såkalt ”definitive gold box edition” som viser at serien ikke har mistet noe av appellen. Det eneste som egentlig røper alderen, er at serien ikke er i widescreen, og at flere av skuespillerne fremdeles er unge og vakre. 17 år etter premieren har de falmet, som mennesker gjør, men Twin Peaks sikrer dem evig liv. Serien handler om et mordmysterium i den lille byen Twin Peaks, et sted langs USAs grense til Canada. Unge, vakre Laura Palmer blir funn...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;html/train/000002.html&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;The Wire (sesong 1-4)&lt;/td&gt;
      &lt;td&gt;train&lt;/td&gt;
      &lt;td&gt;positive&lt;/td&gt;
      &lt;td&gt;I neste uke kommer sesong 5 av tv-serien ”The Wire” på DVD. 2008 har for meg vært sterkt preget av denne serien. Hjemme hos oss begynte vi med sesong 1 i vår. Da hadde jeg i lengre tid hørt panegyriske lovord om serien fra både venner og media. Vi ble også fanget av skildringene av purk og skurk i Baltimore, og pløyde oss igjennom alt til og med sesong 4 på sensommeren. Jeg vil ikke gå så langt som å kalle det ”verdens beste serie”, som noen har gjort, men det er ingen tvil om at dette er noe av det bedre som er blitt vist på tv! Serien forteller om en gruppe politietterforskere som samles...&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;I will use this dataset in future posts to explore various NLP techniques. In the upcoming post we will see if we are able to train a &lt;a href=&quot;https://nlp.fast.ai/classification/2018/05/15/introducing-ulmfit.html&quot;&gt;ULMFiT&lt;/a&gt; classifier on this dataset, and see how it compares to the results for the similar english &lt;a href=&quot;https://paperswithcode.com/sota/sentiment-analysis-on-imdb&quot;&gt;IMDB-dataset&lt;/a&gt;. I also hope to test &lt;a href=&quot;https://nlp.fast.ai/classification/2019/09/10/multifit.html&quot;&gt;MultiFiT&lt;/a&gt; in a later post.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name></name></author><summary type="html"></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://hallvagi.github.io/dl-explorer/images/some_folder/your_image.png" /><media:content medium="image" url="https://hallvagi.github.io/dl-explorer/images/some_folder/your_image.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry></feed>